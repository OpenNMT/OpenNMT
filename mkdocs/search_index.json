{
    "docs": [
        {
            "location": "/",
            "text": "OpenNMT: Open-Source Neural Machine Translation\n\n\nOpenNMT\n is a full-featured,\nopen-source (MIT) neural machine translation system utilizing the\n\nTorch\n mathematical toolkit.\n\n\n\n\nThe system is designed to be simple to use and easy to extend , while\nmaintaining efficiency and state-of-the-art translation\naccuracy. Features include:\n\n\n\n\nSpeed and memory optimizations for high-performance GPU training.\n\n\nSimple general-purpose interface, only requires and source/target data files.\n\n\nC++ implementation of the translator\n for easy deployment.\n\n\nExtensions to allow other sequence generation tasks such as summarization and image captioning.\n\n\n\n\n\n\nInstallation\n\n\nOpenNMT only requires a vanilla Torch install with few dependencies. Alternatively there is a (CUDA) \nDocker container\n.\n\n\n\n\nDependencies\n\n\n\n\nnn\n\n\nnngraph\n\n\ntds\n\n\npenlight\n\n\n\n\nGPU training requires:\n\n\n\n\ncunn\n\n\ncutorch\n\n\n\n\nMulti-GPU training additionally requires:\n\n\n\n\nthreads\n\n\n\n\n\n\nQuickstart\n\n\nOpenNMT consists of three commands:\n\n\n1) Preprocess the data.\n\n\nth preprocess.lua -train_src data/src-train.txt -train_tgt data/tgt-train.txt -valid_src data/src-val.txt -valid_tgt data/tgt-val.txt -save_data data/demo\n\n\n2) Train the model.\n\n\nth train.lua -data data/demo-train.t7 -save_model model\n\n\n3) Translate sentences.\n\n\nth translate.lua -model model_final.t7 -src data/src-test.txt -output pred.txt\n\n\nSee the \nguide\n for more details.\n\n\nCitation\n\n\nA \ntechnical report\n on OpenNMT is available. If you use the system for academic work, please cite:\n\n\n    @ARTICLE{2017opennmt,\n         author = { {Klein}, G. and {Kim}, Y. and {Deng}, Y. \n                    and {Senellart}, J. and {Rush}, A.~M.},\n         title = \n{OpenNMT: Open-Source Toolkit \n                   for Neural Machine Translation}\n,\n         journal = {ArXiv e-prints},\n         eprint = {1701.02810} }\n\n\n\n\nDocumentation\n\n\n\n\nOptions and Features\n \n\n\nDocumentation\n \n\n\nExample Models\n\n\nForum\n\n\nLive Demo\n\n\nBibliography",
            "title": "Home"
        },
        {
            "location": "/#opennmt-open-source-neural-machine-translation",
            "text": "OpenNMT  is a full-featured,\nopen-source (MIT) neural machine translation system utilizing the Torch  mathematical toolkit.   The system is designed to be simple to use and easy to extend , while\nmaintaining efficiency and state-of-the-art translation\naccuracy. Features include:   Speed and memory optimizations for high-performance GPU training.  Simple general-purpose interface, only requires and source/target data files.  C++ implementation of the translator  for easy deployment.  Extensions to allow other sequence generation tasks such as summarization and image captioning.",
            "title": "OpenNMT: Open-Source Neural Machine Translation"
        },
        {
            "location": "/#installation",
            "text": "OpenNMT only requires a vanilla Torch install with few dependencies. Alternatively there is a (CUDA)  Docker container .",
            "title": "Installation"
        },
        {
            "location": "/#dependencies",
            "text": "nn  nngraph  tds  penlight   GPU training requires:   cunn  cutorch   Multi-GPU training additionally requires:   threads",
            "title": "Dependencies"
        },
        {
            "location": "/#quickstart",
            "text": "OpenNMT consists of three commands:  1) Preprocess the data.  th preprocess.lua -train_src data/src-train.txt -train_tgt data/tgt-train.txt -valid_src data/src-val.txt -valid_tgt data/tgt-val.txt -save_data data/demo  2) Train the model.  th train.lua -data data/demo-train.t7 -save_model model  3) Translate sentences.  th translate.lua -model model_final.t7 -src data/src-test.txt -output pred.txt  See the  guide  for more details.",
            "title": "Quickstart"
        },
        {
            "location": "/#citation",
            "text": "A  technical report  on OpenNMT is available. If you use the system for academic work, please cite:      @ARTICLE{2017opennmt,\n         author = { {Klein}, G. and {Kim}, Y. and {Deng}, Y. \n                    and {Senellart}, J. and {Rush}, A.~M.},\n         title =  {OpenNMT: Open-Source Toolkit \n                   for Neural Machine Translation} ,\n         journal = {ArXiv e-prints},\n         eprint = {1701.02810} }",
            "title": "Citation"
        },
        {
            "location": "/#documentation",
            "text": "Options and Features    Documentation    Example Models  Forum  Live Demo  Bibliography",
            "title": "Documentation"
        },
        {
            "location": "/code/data/",
            "text": "",
            "title": "Home"
        },
        {
            "location": "/code/data/onmt+data+Batch/",
            "text": "onmt.Batch\n\n\nA batch of sentences to translate and targets. Manages padding,\n  features, and batch alignment (for efficiency).\n\n\nUsed by the decoder and encoder objects.\n\n\n[src]\n\n\n\n\nonmt.Batch(src, srcFeatures, tgt, tgtFeatures)\n\n\nCreate a batch object.\n\n\nParameters:\n\n\n\n\nsrc\n - 2D table of source batch indices\n\n\nsrcFeatures\n - 2D table of source batch features (opt)\n\n\ntgt\n - 2D table of target batch indices\n\n\ntgtFeatures\n - 2D table of target batch features (opt)\n\n\n\n\n[src]\n\n\n\n\nonmt.Batch:setSourceInput(sourceInput)\n\n\nSet source input directly,\n\n\nParameters:\n\n\n\n\nsourceInput\n - a Tensor of size (sequence_length, batch_size, feature_dim)\n  ,or a sequence of size (sequence_length, batch_size). Be aware that sourceInput is not cloned here.\n\n\n\n\n[src]\n\n\n\n\nonmt.Batch:setTargetInput(targetInput)\n\n\nSet target input directly.\n\n\nParameters:\n\n\n\n\ntargetInput\n - a tensor of size (sequence_length, batch_size). Padded with onmt.Constants.PAD. Be aware that targetInput is not cloned here.\n\n\n\n\n[src]\n\n\n\n\nonmt.Batch:setTargetOutput(targetOutput)\n\n\nSet target output directly.\n\n\nParameters:\n\n\n\n\ntargetOutput\n - a tensor of size (sequence_length, batch_size). Padded with onmt.Constants.PAD.  Be aware that targetOutput is not cloned here.\n\n\n\n\n[src]\n\n\n\n\nonmt.Batch:getSourceInput(t)\n\n\nGet source input batch at timestep \nt\n. \n\n\n[src]\n\n\n\n\nonmt.Batch:getTargetInput(t)\n\n\nGet target input batch at timestep \nt\n. \n\n\n[src]\n\n\n\n\nonmt.Batch:getTargetOutput(t)\n\n\nGet target output batch at timestep \nt\n (values t+1).",
            "title": "onmt+data+Batch"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatch",
            "text": "A batch of sentences to translate and targets. Manages padding,\n  features, and batch alignment (for efficiency).  Used by the decoder and encoder objects.  [src]",
            "title": "onmt.Batch"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatchsrc-srcfeatures-tgt-tgtfeatures",
            "text": "Create a batch object.  Parameters:   src  - 2D table of source batch indices  srcFeatures  - 2D table of source batch features (opt)  tgt  - 2D table of target batch indices  tgtFeatures  - 2D table of target batch features (opt)   [src]",
            "title": "onmt.Batch(src, srcFeatures, tgt, tgtFeatures)"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatchsetsourceinputsourceinput",
            "text": "Set source input directly,  Parameters:   sourceInput  - a Tensor of size (sequence_length, batch_size, feature_dim)\n  ,or a sequence of size (sequence_length, batch_size). Be aware that sourceInput is not cloned here.   [src]",
            "title": "onmt.Batch:setSourceInput(sourceInput)"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatchsettargetinputtargetinput",
            "text": "Set target input directly.  Parameters:   targetInput  - a tensor of size (sequence_length, batch_size). Padded with onmt.Constants.PAD. Be aware that targetInput is not cloned here.   [src]",
            "title": "onmt.Batch:setTargetInput(targetInput)"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatchsettargetoutputtargetoutput",
            "text": "Set target output directly.  Parameters:   targetOutput  - a tensor of size (sequence_length, batch_size). Padded with onmt.Constants.PAD.  Be aware that targetOutput is not cloned here.   [src]",
            "title": "onmt.Batch:setTargetOutput(targetOutput)"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatchgetsourceinputt",
            "text": "Get source input batch at timestep  t .   [src]",
            "title": "onmt.Batch:getSourceInput(t)"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatchgettargetinputt",
            "text": "Get target input batch at timestep  t .   [src]",
            "title": "onmt.Batch:getTargetInput(t)"
        },
        {
            "location": "/code/data/onmt+data+Batch/#onmtbatchgettargetoutputt",
            "text": "Get target output batch at timestep  t  (values t+1).",
            "title": "onmt.Batch:getTargetOutput(t)"
        },
        {
            "location": "/code/data/onmt+data+Dataset/",
            "text": "onmt.Dataset\n\n\nData management and batch creation. Handles data created by \npreprocess.lua\n. \n\n\n[src]\n\n\n\n\nonmt.Dataset(srcData, tgtData)\n\n\nInitialize a data object given aligned tables of IntTensors \nsrcData\n\n  and \ntgtData\n.\n\n\n[src]\n\n\n\n\nonmt.Dataset:setBatchSize(maxBatchSize)\n\n\nSetup up the training data to respect \nmaxBatchSize\n. \n\n\n[src]\n\n\n\n\nonmt.Dataset:batchCount()\n\n\nReturn number of batches. \n\n\n[src]\n\n\n\n\nonmt.Dataset:getBatch(idx)\n\n\nGet \nBatch\n number \nidx\n. If nil make a batch of all the data.",
            "title": "onmt+data+Dataset"
        },
        {
            "location": "/code/data/onmt+data+Dataset/#onmtdataset",
            "text": "Data management and batch creation. Handles data created by  preprocess.lua .   [src]",
            "title": "onmt.Dataset"
        },
        {
            "location": "/code/data/onmt+data+Dataset/#onmtdatasetsrcdata-tgtdata",
            "text": "Initialize a data object given aligned tables of IntTensors  srcData \n  and  tgtData .  [src]",
            "title": "onmt.Dataset(srcData, tgtData)"
        },
        {
            "location": "/code/data/onmt+data+Dataset/#onmtdatasetsetbatchsizemaxbatchsize",
            "text": "Setup up the training data to respect  maxBatchSize .   [src]",
            "title": "onmt.Dataset:setBatchSize(maxBatchSize)"
        },
        {
            "location": "/code/data/onmt+data+Dataset/#onmtdatasetbatchcount",
            "text": "Return number of batches.   [src]",
            "title": "onmt.Dataset:batchCount()"
        },
        {
            "location": "/code/data/onmt+data+Dataset/#onmtdatasetgetbatchidx",
            "text": "Get  Batch  number  idx . If nil make a batch of all the data.",
            "title": "onmt.Dataset:getBatch(idx)"
        },
        {
            "location": "/code/data/onmt+data+Preprocessor/",
            "text": "Preprocessor.lua\n\n\nData Preparation functions.\n\n\n\n\nonmt.Preprocessor\n\n\nUndocumented methods\n\n\n\n * \nonmt.Preprocessor.declareOpts(cmd, mode)\n\n\n\n * \nonmt.Preprocessor(args, mode)\n\n\n\n * \nonmt.Preprocessor:makeBilingualData(srcFile, tgtFile, srcDicts, tgtDicts, isValid)\n\n\n\n * \nonmt.Preprocessor:makeMonolingualData(file, dicts, isValid)",
            "title": "onmt+data+Preprocessor"
        },
        {
            "location": "/code/data/onmt+data+Preprocessor/#preprocessorlua",
            "text": "Data Preparation functions.",
            "title": "Preprocessor.lua"
        },
        {
            "location": "/code/data/onmt+data+Preprocessor/#onmtpreprocessor",
            "text": "",
            "title": "onmt.Preprocessor"
        },
        {
            "location": "/code/data/onmt+data+Preprocessor/#undocumented-methods",
            "text": "*  onmt.Preprocessor.declareOpts(cmd, mode)  \n *  onmt.Preprocessor(args, mode)  \n *  onmt.Preprocessor:makeBilingualData(srcFile, tgtFile, srcDicts, tgtDicts, isValid)  \n *  onmt.Preprocessor:makeMonolingualData(file, dicts, isValid)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/data/onmt+data+Vocabulary/",
            "text": "onmt.Vocabulary\n\n\nVocabulary management utility functions. \n\n\nUndocumented methods\n\n\n\n * \nonmt.Vocabulary.make(filename, validFunc)\n\n\n\n * \nonmt.Vocabulary.init(name, dataFile, vocabFile, vocabSize, featuresVocabsFiles, validFunc)\n\n\n\n * \nonmt.Vocabulary.save(name, vocab, file)\n\n\n\n * \nonmt.Vocabulary.saveFeatures(name, vocabs, prefix)",
            "title": "onmt+data+Vocabulary"
        },
        {
            "location": "/code/data/onmt+data+Vocabulary/#onmtvocabulary",
            "text": "Vocabulary management utility functions.",
            "title": "onmt.Vocabulary"
        },
        {
            "location": "/code/data/onmt+data+Vocabulary/#undocumented-methods",
            "text": "*  onmt.Vocabulary.make(filename, validFunc)  \n *  onmt.Vocabulary.init(name, dataFile, vocabFile, vocabSize, featuresVocabsFiles, validFunc)  \n *  onmt.Vocabulary.save(name, vocab, file)  \n *  onmt.Vocabulary.saveFeatures(name, vocabs, prefix)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/",
            "text": "",
            "title": "Home"
        },
        {
            "location": "/code/modules/onmt+modules+BiEncoder/",
            "text": "onmt.BiEncoder\n\n\nBiEncoder is a bidirectional Sequencer used for the source language.\n\n\nnetFwd\n\n\nh_1 =\n h_2 =\n h_3 =\n ... =\n h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1 =\n h_2 =\n h_3 =\n ... =\n h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n\n\n\n\nnetBwd\n\n\nh_1 \n= h_2 \n= h_3 \n= ... \n= h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1 \n= h_2 \n= h_3 \n= ... \n= h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n\n\n\n\nInherits from \nonmt.Sequencer\n.\n\n\n[src]\n\n\n\n\nonmt.BiEncoder(input, rnn, merge)\n\n\nCreate a bi-encoder.\n\n\nParameters:\n\n\n\n\ninput\n - input neural network.\n\n\nrnn\n - recurrent template module.\n\n\nmerge\n - fwd/bwd merge operation {\"concat\", \"sum\"}\n\n\n\n\n[src]\n\n\n\n\nonmt.BiEncoder.load(pretrained)\n\n\nReturn a new BiEncoder using the serialized data \npretrained\n. \n\n\n[src]\n\n\n\n\nonmt.BiEncoder:serialize()\n\n\nReturn data to serialize. \n\n\nUndocumented methods\n\n\n\n * \nonmt.BiEncoder:resetPreallocation()\n\n\n\n * \nonmt.BiEncoder:maskPadding()\n\n\n\n * \nonmt.BiEncoder:forward(batch)\n\n\n\n * \nonmt.BiEncoder:backward(batch, gradStatesOutput, gradContextOutput)",
            "title": "onmt+modules+BiEncoder"
        },
        {
            "location": "/code/modules/onmt+modules+BiEncoder/#onmtbiencoder",
            "text": "BiEncoder is a bidirectional Sequencer used for the source language.  netFwd  h_1 =  h_2 =  h_3 =  ... =  h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1 =  h_2 =  h_3 =  ... =  h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n  netBwd  h_1  = h_2  = h_3  = ...  = h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1  = h_2  = h_3  = ...  = h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n  Inherits from  onmt.Sequencer .  [src]",
            "title": "onmt.BiEncoder"
        },
        {
            "location": "/code/modules/onmt+modules+BiEncoder/#onmtbiencoderinput-rnn-merge",
            "text": "Create a bi-encoder.  Parameters:   input  - input neural network.  rnn  - recurrent template module.  merge  - fwd/bwd merge operation {\"concat\", \"sum\"}   [src]",
            "title": "onmt.BiEncoder(input, rnn, merge)"
        },
        {
            "location": "/code/modules/onmt+modules+BiEncoder/#onmtbiencoderloadpretrained",
            "text": "Return a new BiEncoder using the serialized data  pretrained .   [src]",
            "title": "onmt.BiEncoder.load(pretrained)"
        },
        {
            "location": "/code/modules/onmt+modules+BiEncoder/#onmtbiencoderserialize",
            "text": "Return data to serialize.",
            "title": "onmt.BiEncoder:serialize()"
        },
        {
            "location": "/code/modules/onmt+modules+BiEncoder/#undocumented-methods",
            "text": "*  onmt.BiEncoder:resetPreallocation()  \n *  onmt.BiEncoder:maskPadding()  \n *  onmt.BiEncoder:forward(batch)  \n *  onmt.BiEncoder:backward(batch, gradStatesOutput, gradContextOutput)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/",
            "text": "onmt.Decoder\n\n\nUnit to decode a sequence of output tokens.\n\n\n .      .      .             .\n |      |      |             |\nh_1 =\n h_2 =\n h_3 =\n ... =\n h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1 =\n h_2 =\n h_3 =\n ... =\n h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n\n\n\n\nInherits from \nonmt.Sequencer\n.\n\n\n[src]\n\n\n\n\nonmt.Decoder(inputNetwork, rnn, generator, inputFeed)\n\n\nConstruct a decoder layer.\n\n\nParameters:\n\n\n\n\ninputNetwork\n - input nn module.\n\n\nrnn\n - recurrent module, such as \nonmt.LSTM\n.\n\n\ngenerator\n - optional, an output \nonmt.Generator\n.\n\n\ninputFeed\n - bool, enable input feeding.\n\n\n\n\n[src]\n\n\n\n\nonmt.Decoder.load(pretrained)\n\n\nReturn a new Decoder using the serialized data \npretrained\n. \n\n\n[src]\n\n\n\n\nonmt.Decoder:serialize()\n\n\nReturn data to serialize. \n\n\n[src]\n\n\n\n\nonmt.Decoder:maskPadding(sourceSizes, sourceLength)\n\n\nMask padding means that the attention-layer is constrained to\n  give zero-weight to padding. This is done by storing a reference\n  to the softmax attention-layer.\n\n\nParameters:\n\n\n\n\nSee  \nonmt.MaskedSoftmax\n.\n\n\n\n\n[src]\n\n\n\n\nonmt.Decoder:forwardOne(input, prevStates, context, prevOut, t)\n\n\nRun one step of the decoder.\n\n\nParameters:\n\n\n\n\ninput\n - input to be passed to inputNetwork.\n\n\nprevStates\n - stack of hidden states (batch x layers*model x rnnSize)\n\n\ncontext\n - encoder output (batch x n x rnnSize)\n\n\nprevOut\n - previous distribution (batch x #words)\n\n\nt\n - current timestep\n\n\n\n\nReturns:\n\n\n\n\nout\n - Top-layer hidden state.\n\n\nstates\n - All states.\n\n\n\n\n[src]\n\n\n\n\nonmt.Decoder:forward(batch, encoderStates, context)\n\n\nCompute all forward steps.\n\n\nParameters:\n\n\n\n\nbatch\n - a \nBatch\n object.\n\n\nencoderStates\n - a batch of initial decoder states (optional) [0]\n\n\ncontext\n - the context to apply attention to.\n\n\n\n\nReturns: Table of top hidden state for each timestep.\n\n\n[src]\n\n\n\n\nonmt.Decoder:backward(batch, outputs, criterion)\n\n\nCompute the backward update.\n\n\nParameters:\n\n\n\n\nbatch\n - a \nBatch\n object\n\n\noutputs\n - expected outputs\n\n\ncriterion\n - a single target criterion object\n\n\n\n\nNote: This code runs both the standard backward and criterion forward/backward.\n  It returns both the gradInputs and the loss.\n  -- \n\n\n[src]\n\n\n\n\nonmt.Decoder:computeLoss(batch, encoderStates, context, criterion)\n\n\nCompute the loss on a batch.\n\n\nParameters:\n\n\n\n\nbatch\n - a \nBatch\n to score.\n\n\nencoderStates\n - initialization of decoder.\n\n\ncontext\n - the attention context.\n\n\ncriterion\n - a pointwise criterion.\n\n\n\n\n[src]\n\n\n\n\nonmt.Decoder:computeScore(batch, encoderStates, context)\n\n\nCompute the score of a batch.\n\n\nParameters:\n\n\n\n\nbatch\n - a \nBatch\n to score.\n\n\nencoderStates\n - initialization of decoder.\n\n\ncontext\n - the attention context.\n\n\n\n\nUndocumented methods\n\n\n\n * \nonmt.Decoder:resetPreallocation()\n\n\n\n * \nonmt.Decoder:forwardAndApply(batch, encoderStates, context, func)",
            "title": "onmt+modules+Decoder"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecoder",
            "text": "Unit to decode a sequence of output tokens.   .      .      .             .\n |      |      |             |\nh_1 =  h_2 =  h_3 =  ... =  h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1 =  h_2 =  h_3 =  ... =  h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n  Inherits from  onmt.Sequencer .  [src]",
            "title": "onmt.Decoder"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecoderinputnetwork-rnn-generator-inputfeed",
            "text": "Construct a decoder layer.  Parameters:   inputNetwork  - input nn module.  rnn  - recurrent module, such as  onmt.LSTM .  generator  - optional, an output  onmt.Generator .  inputFeed  - bool, enable input feeding.   [src]",
            "title": "onmt.Decoder(inputNetwork, rnn, generator, inputFeed)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecoderloadpretrained",
            "text": "Return a new Decoder using the serialized data  pretrained .   [src]",
            "title": "onmt.Decoder.load(pretrained)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecoderserialize",
            "text": "Return data to serialize.   [src]",
            "title": "onmt.Decoder:serialize()"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecodermaskpaddingsourcesizes-sourcelength",
            "text": "Mask padding means that the attention-layer is constrained to\n  give zero-weight to padding. This is done by storing a reference\n  to the softmax attention-layer.  Parameters:   See   onmt.MaskedSoftmax .   [src]",
            "title": "onmt.Decoder:maskPadding(sourceSizes, sourceLength)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecoderforwardoneinput-prevstates-context-prevout-t",
            "text": "Run one step of the decoder.  Parameters:   input  - input to be passed to inputNetwork.  prevStates  - stack of hidden states (batch x layers*model x rnnSize)  context  - encoder output (batch x n x rnnSize)  prevOut  - previous distribution (batch x #words)  t  - current timestep   Returns:   out  - Top-layer hidden state.  states  - All states.   [src]",
            "title": "onmt.Decoder:forwardOne(input, prevStates, context, prevOut, t)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecoderforwardbatch-encoderstates-context",
            "text": "Compute all forward steps.  Parameters:   batch  - a  Batch  object.  encoderStates  - a batch of initial decoder states (optional) [0]  context  - the context to apply attention to.   Returns: Table of top hidden state for each timestep.  [src]",
            "title": "onmt.Decoder:forward(batch, encoderStates, context)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecoderbackwardbatch-outputs-criterion",
            "text": "Compute the backward update.  Parameters:   batch  - a  Batch  object  outputs  - expected outputs  criterion  - a single target criterion object   Note: This code runs both the standard backward and criterion forward/backward.\n  It returns both the gradInputs and the loss.\n  --   [src]",
            "title": "onmt.Decoder:backward(batch, outputs, criterion)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecodercomputelossbatch-encoderstates-context-criterion",
            "text": "Compute the loss on a batch.  Parameters:   batch  - a  Batch  to score.  encoderStates  - initialization of decoder.  context  - the attention context.  criterion  - a pointwise criterion.   [src]",
            "title": "onmt.Decoder:computeLoss(batch, encoderStates, context, criterion)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#onmtdecodercomputescorebatch-encoderstates-context",
            "text": "Compute the score of a batch.  Parameters:   batch  - a  Batch  to score.  encoderStates  - initialization of decoder.  context  - the attention context.",
            "title": "onmt.Decoder:computeScore(batch, encoderStates, context)"
        },
        {
            "location": "/code/modules/onmt+modules+Decoder/#undocumented-methods",
            "text": "*  onmt.Decoder:resetPreallocation()  \n *  onmt.Decoder:forwardAndApply(batch, encoderStates, context, func)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/",
            "text": "onmt.Encoder\n\n\nEncoder is a unidirectional Sequencer used for the source language.\n\n\nh_1 =\n h_2 =\n h_3 =\n ... =\n h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1 =\n h_2 =\n h_3 =\n ... =\n h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n\n\n\n\nInherits from \nonmt.Sequencer\n.\n\n\n[src]\n\n\n\n\nonmt.Encoder(inputNetwork, rnn)\n\n\nConstruct an encoder layer.\n\n\nParameters:\n\n\n\n\ninputNetwork\n - input module.\n\n\nrnn\n - recurrent module.\n\n\n\n\n[src]\n\n\n\n\nonmt.Encoder.load(pretrained)\n\n\nReturn a new Encoder using the serialized data \npretrained\n. \n\n\n[src]\n\n\n\n\nonmt.Encoder:serialize()\n\n\nReturn data to serialize. \n\n\n[src]\n\n\n\n\nonmt.Encoder:forward(batch)\n\n\nCompute the context representation of an input.\n\n\nParameters:\n\n\n\n\nbatch\n - as defined in batch.lua.\n\n\n\n\nReturns:\n\n\n\n\n\n\n\n\nfinal hidden states\n\n\n\n\n\n\n\n\n\n\ncontext matrix H\n\n\n\n\n\n\n\n\n[src]\n\n\n\n\nonmt.Encoder:backward(batch, gradStatesOutput, gradContextOutput)\n\n\nBackward pass (only called during training)\n\n\nParameters:\n\n\n\n\nbatch\n - must be same as for forward\n\n\ngradStatesOutput\n gradient of loss wrt last state - this can be null if states are not used\n\n\ngradContextOutput\n - gradient of loss wrt full context.\n\n\n\n\nReturns: \ngradInputs\n of input network.\n\n\nUndocumented methods\n\n\n\n * \nonmt.Encoder:resetPreallocation()\n\n\n\n * \nonmt.Encoder:maskPadding()",
            "title": "onmt+modules+Encoder"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/#onmtencoder",
            "text": "Encoder is a unidirectional Sequencer used for the source language.  h_1 =  h_2 =  h_3 =  ... =  h_n\n |      |      |             |\n .      .      .             .\n |      |      |             |\nh_1 =  h_2 =  h_3 =  ... =  h_n\n |      |      |             |\n |      |      |             |\nx_1    x_2    x_3           x_n  Inherits from  onmt.Sequencer .  [src]",
            "title": "onmt.Encoder"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/#onmtencoderinputnetwork-rnn",
            "text": "Construct an encoder layer.  Parameters:   inputNetwork  - input module.  rnn  - recurrent module.   [src]",
            "title": "onmt.Encoder(inputNetwork, rnn)"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/#onmtencoderloadpretrained",
            "text": "Return a new Encoder using the serialized data  pretrained .   [src]",
            "title": "onmt.Encoder.load(pretrained)"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/#onmtencoderserialize",
            "text": "Return data to serialize.   [src]",
            "title": "onmt.Encoder:serialize()"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/#onmtencoderforwardbatch",
            "text": "Compute the context representation of an input.  Parameters:   batch  - as defined in batch.lua.   Returns:     final hidden states      context matrix H     [src]",
            "title": "onmt.Encoder:forward(batch)"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/#onmtencoderbackwardbatch-gradstatesoutput-gradcontextoutput",
            "text": "Backward pass (only called during training)  Parameters:   batch  - must be same as for forward  gradStatesOutput  gradient of loss wrt last state - this can be null if states are not used  gradContextOutput  - gradient of loss wrt full context.   Returns:  gradInputs  of input network.",
            "title": "onmt.Encoder:backward(batch, gradStatesOutput, gradContextOutput)"
        },
        {
            "location": "/code/modules/onmt+modules+Encoder/#undocumented-methods",
            "text": "*  onmt.Encoder:resetPreallocation()  \n *  onmt.Encoder:maskPadding()",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/onmt+modules+FeaturesEmbedding/",
            "text": "onmt.FeaturesEmbedding\n\n\nA nngraph unit that maps features ids to embeddings. When using multiple\n  features this can be the concatenation or the sum of each individual embedding.\n\n\nUndocumented methods\n\n\n\n * \nonmt.FeaturesEmbedding(vocabSizes, vecSizes, merge)",
            "title": "onmt+modules+FeaturesEmbedding"
        },
        {
            "location": "/code/modules/onmt+modules+FeaturesEmbedding/#onmtfeaturesembedding",
            "text": "A nngraph unit that maps features ids to embeddings. When using multiple\n  features this can be the concatenation or the sum of each individual embedding.",
            "title": "onmt.FeaturesEmbedding"
        },
        {
            "location": "/code/modules/onmt+modules+FeaturesEmbedding/#undocumented-methods",
            "text": "*  onmt.FeaturesEmbedding(vocabSizes, vecSizes, merge)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/onmt+modules+FeaturesGenerator/",
            "text": "onmt.FeaturesGenerator\n\n\nFeature decoder generator. Given RNN state, produce categorical distribution over\ntokens and features.\n\n\nImplements \n[softmax(W^1 h + b^1), softmax(W^2 h + b^2), ..., softmax(W^n h + b^n)] \n.\n\n\n[src]\n\n\n\n\nonmt.FeaturesGenerator(rnnSize, outputSizes)\n\n\nParameters:\n\n\n\n\nrnnSize\n - Input rnn size.\n\n\noutputSizes\n - Table of each output size.",
            "title": "onmt+modules+FeaturesGenerator"
        },
        {
            "location": "/code/modules/onmt+modules+FeaturesGenerator/#onmtfeaturesgenerator",
            "text": "Feature decoder generator. Given RNN state, produce categorical distribution over\ntokens and features.  Implements  [softmax(W^1 h + b^1), softmax(W^2 h + b^2), ..., softmax(W^n h + b^n)]  .  [src]",
            "title": "onmt.FeaturesGenerator"
        },
        {
            "location": "/code/modules/onmt+modules+FeaturesGenerator/#onmtfeaturesgeneratorrnnsize-outputsizes",
            "text": "Parameters:   rnnSize  - Input rnn size.  outputSizes  - Table of each output size.",
            "title": "onmt.FeaturesGenerator(rnnSize, outputSizes)"
        },
        {
            "location": "/code/modules/onmt+modules+GRU/",
            "text": "onmt.GRU\n\n\nImplementation of a single stacked-GRU step as\nan nn unit.\n\n\n  h^L_{t-1} --- h^L_t\n             |\n\n\n             .\n             |\n         [dropout]\n             |\n  h^1_{t-1} --- h^1_t\n             |\n             |\n            x_t\n\n\n\nComputes \n(h_{t-1}, x_t) => (h_{t})\n.\n\n\n[src]\n\n\n\n\nonmt.GRU(layers, inputSize, hiddenSize, dropout, residual)\n\n\nParameters:\n\n\n\n\nlayers\n - Number of layers\n\n\ninputSize\n - Size of input layer\n\n\nhiddenSize\n - Size of the hidden layers\n\n\ndropout\n - Dropout rate to use (should be in \n[0,1]\n range.\n\n\nresidual\n - Residual connections between layers (boolean)",
            "title": "onmt+modules+GRU"
        },
        {
            "location": "/code/modules/onmt+modules+GRU/#onmtgru",
            "text": "Implementation of a single stacked-GRU step as\nan nn unit.    h^L_{t-1} --- h^L_t\n             |\n\n\n             .\n             |\n         [dropout]\n             |\n  h^1_{t-1} --- h^1_t\n             |\n             |\n            x_t  Computes  (h_{t-1}, x_t) => (h_{t}) .  [src]",
            "title": "onmt.GRU"
        },
        {
            "location": "/code/modules/onmt+modules+GRU/#onmtgrulayers-inputsize-hiddensize-dropout-residual",
            "text": "Parameters:   layers  - Number of layers  inputSize  - Size of input layer  hiddenSize  - Size of the hidden layers  dropout  - Dropout rate to use (should be in  [0,1]  range.  residual  - Residual connections between layers (boolean)",
            "title": "onmt.GRU(layers, inputSize, hiddenSize, dropout, residual)"
        },
        {
            "location": "/code/modules/onmt+modules+Generator/",
            "text": "onmt.Generator\n\n\nDefault decoder generator. Given RNN state, produce categorical distribution.\n\n\nSimply implements \nsoftmax(W h + b)\n.\n\n\nUndocumented methods\n\n\n\n * \nonmt.Generator(rnnSize, outputSize)\n\n\n\n * \nonmt.Generator:updateOutput(input)\n\n\n\n * \nonmt.Generator:updateGradInput(input, gradOutput)\n\n\n\n * \nonmt.Generator:accGradParameters(input, gradOutput, scale)",
            "title": "onmt+modules+Generator"
        },
        {
            "location": "/code/modules/onmt+modules+Generator/#onmtgenerator",
            "text": "Default decoder generator. Given RNN state, produce categorical distribution.  Simply implements  softmax(W h + b) .",
            "title": "onmt.Generator"
        },
        {
            "location": "/code/modules/onmt+modules+Generator/#undocumented-methods",
            "text": "*  onmt.Generator(rnnSize, outputSize)  \n *  onmt.Generator:updateOutput(input)  \n *  onmt.Generator:updateGradInput(input, gradOutput)  \n *  onmt.Generator:accGradParameters(input, gradOutput, scale)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/onmt+modules+GlobalAttention/",
            "text": "onmt.GlobalAttention\n\n\nGlobal attention takes a matrix and a query vector. It\nthen computes a parameterized convex combination of the matrix\nbased on the input query.\n\n\nH_1 H_2 H_3 ... H_n\n q   q   q       q\n  |  |   |       |\n   \\ |   |      /\n       .....\n     \\   |  /\n         a\n\n\n\nConstructs a unit mapping:\n  \n(H_1 .. H_n, q) => (a)\n\n  Where H is of \nbatch x n x dim\n and q is of \nbatch x dim\n.\n\n\nThe full function is  \n\\tanh(W_2 [(softmax((W_1 q + b_1) H) H), q] + b_2)\n.\n\n\n[src]\n\n\n\n\nonmt.GlobalAttention(dim)\n\n\nA nn-style module computing attention.\n\n\nParameters:\n\n\n\n\ndim\n - dimension of the context vectors.",
            "title": "onmt+modules+GlobalAttention"
        },
        {
            "location": "/code/modules/onmt+modules+GlobalAttention/#onmtglobalattention",
            "text": "Global attention takes a matrix and a query vector. It\nthen computes a parameterized convex combination of the matrix\nbased on the input query.  H_1 H_2 H_3 ... H_n\n q   q   q       q\n  |  |   |       |\n   \\ |   |      /\n       .....\n     \\   |  /\n         a  Constructs a unit mapping:\n   (H_1 .. H_n, q) => (a) \n  Where H is of  batch x n x dim  and q is of  batch x dim .  The full function is   \\tanh(W_2 [(softmax((W_1 q + b_1) H) H), q] + b_2) .  [src]",
            "title": "onmt.GlobalAttention"
        },
        {
            "location": "/code/modules/onmt+modules+GlobalAttention/#onmtglobalattentiondim",
            "text": "A nn-style module computing attention.  Parameters:   dim  - dimension of the context vectors.",
            "title": "onmt.GlobalAttention(dim)"
        },
        {
            "location": "/code/modules/onmt+modules+LSTM/",
            "text": "onmt.LSTM\n\n\nImplementation of a single stacked-LSTM step as\nan nn unit.\n\n\n  h^L_{t-1} --- h^L_t\n  c^L_{t-1} --- c^L_t\n             |\n\n\n             .\n             |\n         [dropout]\n             |\n  h^1_{t-1} --- h^1_t\n  c^1_{t-1} --- c^1_t\n             |\n             |\n            x_t\n\n\n\nComputes \n(c_{t-1}, h_{t-1}, x_t) => (c_{t}, h_{t})\n.\n\n\n[src]\n\n\n\n\nonmt.LSTM(layers, inputSize, hiddenSize, dropout, residual)\n\n\nParameters:\n\n\n\n\nlayers\n - Number of LSTM layers, L.\n\n\ninputSize\n - Size of input layer\n\n\nhiddenSize\n - Size of the hidden layers.\n\n\ndropout\n - Dropout rate to use.\n\n\nresidual\n - Residual connections between layers.",
            "title": "onmt+modules+LSTM"
        },
        {
            "location": "/code/modules/onmt+modules+LSTM/#onmtlstm",
            "text": "Implementation of a single stacked-LSTM step as\nan nn unit.    h^L_{t-1} --- h^L_t\n  c^L_{t-1} --- c^L_t\n             |\n\n\n             .\n             |\n         [dropout]\n             |\n  h^1_{t-1} --- h^1_t\n  c^1_{t-1} --- c^1_t\n             |\n             |\n            x_t  Computes  (c_{t-1}, h_{t-1}, x_t) => (c_{t}, h_{t}) .  [src]",
            "title": "onmt.LSTM"
        },
        {
            "location": "/code/modules/onmt+modules+LSTM/#onmtlstmlayers-inputsize-hiddensize-dropout-residual",
            "text": "Parameters:   layers  - Number of LSTM layers, L.  inputSize  - Size of input layer  hiddenSize  - Size of the hidden layers.  dropout  - Dropout rate to use.  residual  - Residual connections between layers.",
            "title": "onmt.LSTM(layers, inputSize, hiddenSize, dropout, residual)"
        },
        {
            "location": "/code/modules/onmt+modules+MaskedSoftmax/",
            "text": "onmt.MaskedSoftmax\n\n\nA batched-softmax wrapper to mask the probabilities of padding.\n\n\nFor instance there may be a batch of instances where A is padding.\n\n\nXXXXAA\nXXAAAA\nXXXXXX\n\n\n\nMaskedSoftmax ensures that no probability is given to the A's.\n\n\nFor this example, \nsourceSizes\n is {4, 2, 6} and \nsourceLength\n is 6.\n\n\n[src]\n\n\n\n\nonmt.MaskedSoftmax(sourceSizes, sourceLength)\n\n\nA nn-style module that applies a softmax on input that gives no weight to the left padding.\n\n\nParameters:\n\n\n\n\nsourceSizes\n -  the true lengths (with left padding).\n\n\nsourceLength\n - the length of the batch.",
            "title": "onmt+modules+MaskedSoftmax"
        },
        {
            "location": "/code/modules/onmt+modules+MaskedSoftmax/#onmtmaskedsoftmax",
            "text": "A batched-softmax wrapper to mask the probabilities of padding.  For instance there may be a batch of instances where A is padding.  XXXXAA\nXXAAAA\nXXXXXX  MaskedSoftmax ensures that no probability is given to the A's.  For this example,  sourceSizes  is {4, 2, 6} and  sourceLength  is 6.  [src]",
            "title": "onmt.MaskedSoftmax"
        },
        {
            "location": "/code/modules/onmt+modules+MaskedSoftmax/#onmtmaskedsoftmaxsourcesizes-sourcelength",
            "text": "A nn-style module that applies a softmax on input that gives no weight to the left padding.  Parameters:   sourceSizes  -  the true lengths (with left padding).  sourceLength  - the length of the batch.",
            "title": "onmt.MaskedSoftmax(sourceSizes, sourceLength)"
        },
        {
            "location": "/code/modules/onmt+modules+Network/",
            "text": "onmt.Network\n\n\nWrapper around a single network. \n\n\nUndocumented methods\n\n\n\n * \nonmt.Network(net)\n\n\n\n * \nonmt.Network:updateOutput(input)\n\n\n\n * \nonmt.Network:updateGradInput(input, gradOutput)\n\n\n\n * \nonmt.Network:accGradParameters(input, gradOutput, scale)",
            "title": "onmt+modules+Network"
        },
        {
            "location": "/code/modules/onmt+modules+Network/#onmtnetwork",
            "text": "Wrapper around a single network.",
            "title": "onmt.Network"
        },
        {
            "location": "/code/modules/onmt+modules+Network/#undocumented-methods",
            "text": "*  onmt.Network(net)  \n *  onmt.Network:updateOutput(input)  \n *  onmt.Network:updateGradInput(input, gradOutput)  \n *  onmt.Network:accGradParameters(input, gradOutput, scale)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/onmt+modules+ParallelClassNLLCriterion/",
            "text": "onmt.ParallelClassNLLCriterion\n\n\nDefine parallel ClassNLLCriterion.\n\n\nUndocumented methods\n\n\n\n * \nonmt.ParallelClassNLLCriterion(outputSizes)",
            "title": "onmt+modules+ParallelClassNLLCriterion"
        },
        {
            "location": "/code/modules/onmt+modules+ParallelClassNLLCriterion/#onmtparallelclassnllcriterion",
            "text": "Define parallel ClassNLLCriterion.",
            "title": "onmt.ParallelClassNLLCriterion"
        },
        {
            "location": "/code/modules/onmt+modules+ParallelClassNLLCriterion/#undocumented-methods",
            "text": "*  onmt.ParallelClassNLLCriterion(outputSizes)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/modules/onmt+modules+Sequencer/",
            "text": "onmt.Sequencer\n\n\nSequencer is the base class for encoder and decoder models.\n  Main task is to manage \nself.net(t)\n, the unrolled network\n  used during training.\n\n\n :net(1) =\n :net(2) =\n ... =\n :net(n-1) =\n :net(n)\n\n\n\n[src]\n\n\n\n\nonmt.Sequencer(network)\n\n\nParameters:\n\n\n\n\nnetwork\n - recurrent step template.\n\n\n\n\n[src]\n\n\n\n\nonmt.Sequencer:net(t)\n\n\nGet access to the recurrent unit at a timestep.\n\n\nParameters:\n  * \nt\n - timestep.\n\n\nReturns: The raw network clone at timestep t.\n  When \nevaluate()\n has been called, cheat and return t=1.\n\n\n[src]\n\n\n\n\nonmt.Sequencer:training()\n\n\nMove the network to train mode. \n\n\n[src]\n\n\n\n\nonmt.Sequencer:evaluate()\n\n\nMove the network to evaluation mode.",
            "title": "onmt+modules+Sequencer"
        },
        {
            "location": "/code/modules/onmt+modules+Sequencer/#onmtsequencer",
            "text": "Sequencer is the base class for encoder and decoder models.\n  Main task is to manage  self.net(t) , the unrolled network\n  used during training.   :net(1) =  :net(2) =  ... =  :net(n-1) =  :net(n)  [src]",
            "title": "onmt.Sequencer"
        },
        {
            "location": "/code/modules/onmt+modules+Sequencer/#onmtsequencernetwork",
            "text": "Parameters:   network  - recurrent step template.   [src]",
            "title": "onmt.Sequencer(network)"
        },
        {
            "location": "/code/modules/onmt+modules+Sequencer/#onmtsequencernett",
            "text": "Get access to the recurrent unit at a timestep.  Parameters:\n  *  t  - timestep.  Returns: The raw network clone at timestep t.\n  When  evaluate()  has been called, cheat and return t=1.  [src]",
            "title": "onmt.Sequencer:net(t)"
        },
        {
            "location": "/code/modules/onmt+modules+Sequencer/#onmtsequencertraining",
            "text": "Move the network to train mode.   [src]",
            "title": "onmt.Sequencer:training()"
        },
        {
            "location": "/code/modules/onmt+modules+Sequencer/#onmtsequencerevaluate",
            "text": "Move the network to evaluation mode.",
            "title": "onmt.Sequencer:evaluate()"
        },
        {
            "location": "/code/modules/onmt+modules+WordEmbedding/",
            "text": "onmt.WordEmbedding\n\n\nnn unit. Maps from word ids to embeddings. Slim wrapper around\nnn.LookupTable to allow fixed and pretrained embeddings.\n\n\n[src]\n\n\n\n\nonmt.WordEmbedding(vocabSize, vecSize, preTrained, fix)\n\n\nParameters:\n\n\n\n\nvocabSize\n - size of the vocabulary\n\n\nvecSize\n - size of the embedding\n\n\npreTrainined\n - path to a pretrained vector file\n\n\nfix\n - keep the weights of the embeddings fixed.\n\n\n\n\nUndocumented methods\n\n\n\n * \nonmt.WordEmbedding:postParametersInitialization()\n\n\n\n * \nonmt.WordEmbedding:accGradParameters(input, gradOutput, scale)\n\n\n\n * \nonmt.WordEmbedding:parameters()",
            "title": "onmt+modules+WordEmbedding"
        },
        {
            "location": "/code/modules/onmt+modules+WordEmbedding/#onmtwordembedding",
            "text": "nn unit. Maps from word ids to embeddings. Slim wrapper around\nnn.LookupTable to allow fixed and pretrained embeddings.  [src]",
            "title": "onmt.WordEmbedding"
        },
        {
            "location": "/code/modules/onmt+modules+WordEmbedding/#onmtwordembeddingvocabsize-vecsize-pretrained-fix",
            "text": "Parameters:   vocabSize  - size of the vocabulary  vecSize  - size of the embedding  preTrainined  - path to a pretrained vector file  fix  - keep the weights of the embeddings fixed.",
            "title": "onmt.WordEmbedding(vocabSize, vecSize, preTrained, fix)"
        },
        {
            "location": "/code/modules/onmt+modules+WordEmbedding/#undocumented-methods",
            "text": "*  onmt.WordEmbedding:postParametersInitialization()  \n *  onmt.WordEmbedding:accGradParameters(input, gradOutput, scale)  \n *  onmt.WordEmbedding:parameters()",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/train/",
            "text": "",
            "title": "Home"
        },
        {
            "location": "/code/train/onmt+train+Checkpoint/",
            "text": "onmt.Checkpoint\n\n\nClass for saving and loading models during training.\n\n\n[src]\n\n\n\n\nonmt.Checkpoint:saveIteration(iteration, epochState, batchOrder, verbose)\n\n\nSave the model and data in the middle of an epoch sorting the iteration. \n\n\nUndocumented methods\n\n\n\n * \nonmt.Checkpoint.declareOpts(cmd)\n\n\n\n * \nonmt.Checkpoint(opt, model, optim, dicts)\n\n\n\n * \nonmt.Checkpoint:save(filePath, info)\n\n\n\n * \nonmt.Checkpoint:saveEpoch(validPpl, epochState, verbose)\n\n\n\n * \nonmt.Checkpoint.loadFromCheckpoint(opt)",
            "title": "onmt+train+Checkpoint"
        },
        {
            "location": "/code/train/onmt+train+Checkpoint/#onmtcheckpoint",
            "text": "Class for saving and loading models during training.  [src]",
            "title": "onmt.Checkpoint"
        },
        {
            "location": "/code/train/onmt+train+Checkpoint/#onmtcheckpointsaveiterationiteration-epochstate-batchorder-verbose",
            "text": "Save the model and data in the middle of an epoch sorting the iteration.",
            "title": "onmt.Checkpoint:saveIteration(iteration, epochState, batchOrder, verbose)"
        },
        {
            "location": "/code/train/onmt+train+Checkpoint/#undocumented-methods",
            "text": "*  onmt.Checkpoint.declareOpts(cmd)  \n *  onmt.Checkpoint(opt, model, optim, dicts)  \n *  onmt.Checkpoint:save(filePath, info)  \n *  onmt.Checkpoint:saveEpoch(validPpl, epochState, verbose)  \n *  onmt.Checkpoint.loadFromCheckpoint(opt)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/train/onmt+train+EpochState/",
            "text": "onmt.EpochState\n\n\nClass for managing the training process by logging and storing\n  the state of the current epoch.\n\n\n[src]\n\n\n\n\nonmt.EpochState(epoch, startIterations, numIterations, learningRate)\n\n\nInitialize for epoch \nepoch\n\n\n[src]\n\n\n\n\nonmt.EpochState:update(model, batch, loss)\n\n\nUpdate training status. Takes \nbatch\n (described in data.lua) and last loss.\n\n\n[src]\n\n\n\n\nonmt.EpochState:log(iteration)\n\n\nLog to status stdout. \n\n\nUndocumented methods\n\n\n\n * \nonmt.EpochState:reset()\n\n\n\n * \nonmt.EpochState:getTime()",
            "title": "onmt+train+EpochState"
        },
        {
            "location": "/code/train/onmt+train+EpochState/#onmtepochstate",
            "text": "Class for managing the training process by logging and storing\n  the state of the current epoch.  [src]",
            "title": "onmt.EpochState"
        },
        {
            "location": "/code/train/onmt+train+EpochState/#onmtepochstateepoch-startiterations-numiterations-learningrate",
            "text": "Initialize for epoch  epoch  [src]",
            "title": "onmt.EpochState(epoch, startIterations, numIterations, learningRate)"
        },
        {
            "location": "/code/train/onmt+train+EpochState/#onmtepochstateupdatemodel-batch-loss",
            "text": "Update training status. Takes  batch  (described in data.lua) and last loss.  [src]",
            "title": "onmt.EpochState:update(model, batch, loss)"
        },
        {
            "location": "/code/train/onmt+train+EpochState/#onmtepochstatelogiteration",
            "text": "Log to status stdout.",
            "title": "onmt.EpochState:log(iteration)"
        },
        {
            "location": "/code/train/onmt+train+EpochState/#undocumented-methods",
            "text": "*  onmt.EpochState:reset()  \n *  onmt.EpochState:getTime()",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/train/onmt+train+Optim/",
            "text": "onmt.Optim\n\n\n\n\n[src]\n\n\n\n\nonmt.Optim:updateLearningRate(score, epoch)\n\n\ndecay learning rate if val perf does not improve or we hit the startDecayAt limit\n\n\nUndocumented methods\n\n\n\n * \nonmt.Optim.declareOpts(cmd)\n\n\n\n * \nonmt.Optim(args, optimStates)\n\n\n\n * \nonmt.Optim:setOptimStates(num)\n\n\n\n * \nonmt.Optim:zeroGrad(gradParams)\n\n\n\n * \nonmt.Optim:prepareGrad(gradParams)\n\n\n\n * \nonmt.Optim:updateParams(params, gradParams)\n\n\n\n * \nonmt.Optim:getLearningRate()\n\n\n\n * \nonmt.Optim:getStates()",
            "title": "onmt+train+Optim"
        },
        {
            "location": "/code/train/onmt+train+Optim/#onmtoptim",
            "text": "[src]",
            "title": "onmt.Optim"
        },
        {
            "location": "/code/train/onmt+train+Optim/#onmtoptimupdatelearningratescore-epoch",
            "text": "decay learning rate if val perf does not improve or we hit the startDecayAt limit",
            "title": "onmt.Optim:updateLearningRate(score, epoch)"
        },
        {
            "location": "/code/train/onmt+train+Optim/#undocumented-methods",
            "text": "*  onmt.Optim.declareOpts(cmd)  \n *  onmt.Optim(args, optimStates)  \n *  onmt.Optim:setOptimStates(num)  \n *  onmt.Optim:zeroGrad(gradParams)  \n *  onmt.Optim:prepareGrad(gradParams)  \n *  onmt.Optim:updateParams(params, gradParams)  \n *  onmt.Optim:getLearningRate()  \n *  onmt.Optim:getStates()",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/train/onmt+train+Trainer/",
            "text": "onmt.Trainer\n\n\n\n\nUndocumented methods\n\n\n\n * \nonmt.Trainer.declareOpts(cmd)\n\n\n\n * \nonmt.Trainer(args)\n\n\n\n * \nonmt.Trainer:train(model, optim, trainData, validData, dataset, info)",
            "title": "onmt+train+Trainer"
        },
        {
            "location": "/code/train/onmt+train+Trainer/#onmttrainer",
            "text": "",
            "title": "onmt.Trainer"
        },
        {
            "location": "/code/train/onmt+train+Trainer/#undocumented-methods",
            "text": "*  onmt.Trainer.declareOpts(cmd)  \n *  onmt.Trainer(args)  \n *  onmt.Trainer:train(model, optim, trainData, validData, dataset, info)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/translate/",
            "text": "",
            "title": "Home"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/",
            "text": "onmt.Advancer\n\n\nClass for specifying how to advance one step. A beam mainly consists of\n  a list of \ntokens\n and a \nstate\n. \ntokens[t]\n stores a flat tensors of size\n  \nbatchSize * beamSize\n representing tokens at step \nt\n. \nstate\n can be either\n  a tensor with first dimension size \nbatchSize * beamSize\n, or an iterable\n  object containing several such tensors.\n\n\nPseudocode:\n\n\n  finished = []\n\n  beams = {}\n\n  -- Initialize the beam.\n\n  [ beams[1] ] \n-- initBeam()\n\n  FOR t = 1, ... DO\n\n    -- Update beam states based on new tokens.\n\n    update([ beams[t] ])\n\n    -- Expand beams by all possible tokens and return the scores.\n\n    [ [scores] ] \n-- expand([ beams[t] ])\n\n    -- Find k best next beams (maintained by BeamSearcher).\n\n    _findKBest([beams], [ [scores] ])\n\n    completed \n-- isComplete([ beams[t + 1] ])\n\n    -- Remove completed hypotheses (maintained by BeamSearcher).\n\n    finished += _completeHypotheses([beams], completed)\n\n    IF all(completed) THEN\n\n      BREAK\n\n    END\n\n  ENDWHILE\n\n\n\n==================================================================\n\n\n[src]\n\n\n\n\nonmt.Advancer:initBeam()\n\n\nReturns an initial beam.\n\n\nReturns:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\n[src]\n\n\n\n\nonmt.Advancer:update(beam)\n\n\nUpdates beam states given new tokens.\n\n\nParameters:\n\n\n\n\nbeam\n - beam with updated token list.\n\n\n\n\n[src]\n\n\n\n\nonmt.Advancer:expand(beam)\n\n\nExpands beam by all possible tokens and returns the scores.\n\n\nParameters:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\nReturns:\n\n\n\n\nscores\n - a 2D tensor of size \n(batchSize * beamSize, numTokens)\n.\n\n\n\n\n[src]\n\n\n\n\nonmt.Advancer:isComplete(beam)\n\n\nChecks which hypotheses in the beam are already finished.\n\n\nParameters:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\nReturns: a binary flat tensor of size \n(batchSize * beamSize)\n, indicating\n  which hypotheses are finished.\n\n\n[src]\n\n\n\n\nonmt.Advancer:setKeptStateIndexes(indexes)\n\n\nSpecifies which states to keep track of. After beam search, those states\n  can be retrieved during all steps along with the tokens. This is used\n  for memory efficiency.\n\n\nParameters:\n\n\n\n\nindexes\n - a table of iterators, specifying the indexes in the \nstates\n to track.\n\n\n\n\n[src]\n\n\n\n\nonmt.Advancer:filter()\n\n\nChecks which hypotheses in the beam shall be pruned.\n\n\nParameters:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\nReturns: a binary flat tensor of size \n(batchSize * beamSize)\n, indicating\n  which beams shall be pruned.",
            "title": "onmt+translate+Advancer"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/#onmtadvancer",
            "text": "Class for specifying how to advance one step. A beam mainly consists of\n  a list of  tokens  and a  state .  tokens[t]  stores a flat tensors of size\n   batchSize * beamSize  representing tokens at step  t .  state  can be either\n  a tensor with first dimension size  batchSize * beamSize , or an iterable\n  object containing several such tensors.  Pseudocode:    finished = []\n\n  beams = {}\n\n  -- Initialize the beam.\n\n  [ beams[1] ]  -- initBeam()\n\n  FOR t = 1, ... DO\n\n    -- Update beam states based on new tokens.\n\n    update([ beams[t] ])\n\n    -- Expand beams by all possible tokens and return the scores.\n\n    [ [scores] ]  -- expand([ beams[t] ])\n\n    -- Find k best next beams (maintained by BeamSearcher).\n\n    _findKBest([beams], [ [scores] ])\n\n    completed  -- isComplete([ beams[t + 1] ])\n\n    -- Remove completed hypotheses (maintained by BeamSearcher).\n\n    finished += _completeHypotheses([beams], completed)\n\n    IF all(completed) THEN\n\n      BREAK\n\n    END\n\n  ENDWHILE  ==================================================================  [src]",
            "title": "onmt.Advancer"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/#onmtadvancerinitbeam",
            "text": "Returns an initial beam.  Returns:   beam  - an  onmt.translate.Beam  object.   [src]",
            "title": "onmt.Advancer:initBeam()"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/#onmtadvancerupdatebeam",
            "text": "Updates beam states given new tokens.  Parameters:   beam  - beam with updated token list.   [src]",
            "title": "onmt.Advancer:update(beam)"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/#onmtadvancerexpandbeam",
            "text": "Expands beam by all possible tokens and returns the scores.  Parameters:   beam  - an  onmt.translate.Beam  object.   Returns:   scores  - a 2D tensor of size  (batchSize * beamSize, numTokens) .   [src]",
            "title": "onmt.Advancer:expand(beam)"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/#onmtadvanceriscompletebeam",
            "text": "Checks which hypotheses in the beam are already finished.  Parameters:   beam  - an  onmt.translate.Beam  object.   Returns: a binary flat tensor of size  (batchSize * beamSize) , indicating\n  which hypotheses are finished.  [src]",
            "title": "onmt.Advancer:isComplete(beam)"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/#onmtadvancersetkeptstateindexesindexes",
            "text": "Specifies which states to keep track of. After beam search, those states\n  can be retrieved during all steps along with the tokens. This is used\n  for memory efficiency.  Parameters:   indexes  - a table of iterators, specifying the indexes in the  states  to track.   [src]",
            "title": "onmt.Advancer:setKeptStateIndexes(indexes)"
        },
        {
            "location": "/code/translate/onmt+translate+Advancer/#onmtadvancerfilter",
            "text": "Checks which hypotheses in the beam shall be pruned.  Parameters:   beam  - an  onmt.translate.Beam  object.   Returns: a binary flat tensor of size  (batchSize * beamSize) , indicating\n  which beams shall be pruned.",
            "title": "onmt.Advancer:filter()"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/",
            "text": "onmt.Beam\n\n\nClass for maintaining statistics of each step. A beam mainly consists of\n  a list of tokens \ntokens\n and a state \nstate\n. \ntokens[t]\n stores a flat tensor\n  of size \nbatchSize * beamSize\n representing the tokens at step \nt\n, while\n  \nstate\n can be either a tensor with first dimension size \nbatchSize * beamSize\n,\n  or an iterable object containing several such tensors.\n\n\n[src]\n\n\n\n\nonmt.Beam(token, state, batchSize)\n\n\nConstructor. We allow users to either specify all initial hypotheses by\n  passing in \ntoken\n and \nstate\n with first dimension \nbatchSize * beamSize\n\n  such that there are \nbeamSize\n initial hypotheses for every sequence in the\n  batch and pass in the number of sequences \nbatchSize\n, or only specify one\n  hypothesis per sequence by passing \ntoken\n and \nstate\n with first dimension\n  \nbatchSize\n, and then \nonmt.translate.BeamSearcher\n will pad with auxiliary\n  hypotheses with scores \n-inf\n such that each sequence starts with \nbeamSize\n\n  hypotheses as in the former case.\n\n\nParameters:\n\n\n\n\ntoken\n - tensor of size \n(batchSize, vocabSize)\n (if start with one initial\n  hypothesis per sequence) or \n(batchSize * beamSize, vocabSize)\n (if start with\n  \nbeamSize\n initial hypotheses per sequence), or a list of such tensors.\n\n\nstate\n - an iterable object, where the contained tensors should have the\n  same first dimension as \ntoken\n.\n\n\nbatchSize\n - optional, number of sentences. Only necessary if\n  start with \nbeamSize\n hypotheses per sequence. [\ntoken:size(1)\n]\n\n\n\n\n[src]\n\n\n\n\nonmt.Beam:getTokens()\n\n\nReturns:\n\n\n\n\ntokens\n - a list of tokens. Note that the start-of-sequence symbols are\n  also included. \ntokens[t]\n stores the tokens at step \nt\n, which is a tensor\n  of size \nbatchSize * beamSize\n.\n\n\n\n\n[src]\n\n\n\n\nonmt.Beam:getState()\n\n\nReturns:\n\n\n\n\nstate\n - an abstract iterable object as passed by constructor. Every tensor\n  inside the \nstate\n has first dimension \nbatchSize * beamSize\n\n\n\n\n[src]\n\n\n\n\nonmt.Beam:getScores()\n\n\nReturns:\n\n\n\n\nscores\n - a flat tensor storing the total scores for each batch. It is of\n  size \nbatchSize * beamSize\n.\n\n\n\n\n[src]\n\n\n\n\nonmt.Beam:getBackPointer()\n\n\nReturns:\n\n\n\n\nbackPointer\n - a flat tensor storing the backpointers for each batch. It is\n  of size \nbatchSize * beamSize\n\n\n\n\n[src]\n\n\n\n\nonmt.Beam:getRemaining()\n\n\nReturns the number of unfinished sequences. The finished sequences will be\n  removed from batch.\n\n\nReturns:\n\n\n\n\nremaining\n - the number of unfinished sequences.\n\n\n\n\n[src]\n\n\n\n\nonmt.Beam:remaining2Orig(remainingId)\n\n\nSince finished sequences are being removed from the batch, this function\n  provides a way to convert the remaining batch id to the original batch id.\n\n\n[src]\n\n\n\n\nonmt.Beam:orig2Remaining(origId)\n\n\nSince finished sequences are being removed from the batch, this function\n  provides a way to convert the original batch id to the remaining batch id.\n\n\n[src]\n\n\n\n\nonmt.Beam:setState(state)\n\n\nSet state.\n\n\n[src]\n\n\n\n\nonmt.Beam:setScores(scores)\n\n\nSet scores.\n\n\n[src]\n\n\n\n\nonmt.Beam:setBackPointer(backPointer)\n\n\nSet backPointer.",
            "title": "onmt+translate+Beam"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeam",
            "text": "Class for maintaining statistics of each step. A beam mainly consists of\n  a list of tokens  tokens  and a state  state .  tokens[t]  stores a flat tensor\n  of size  batchSize * beamSize  representing the tokens at step  t , while\n   state  can be either a tensor with first dimension size  batchSize * beamSize ,\n  or an iterable object containing several such tensors.  [src]",
            "title": "onmt.Beam"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamtoken-state-batchsize",
            "text": "Constructor. We allow users to either specify all initial hypotheses by\n  passing in  token  and  state  with first dimension  batchSize * beamSize \n  such that there are  beamSize  initial hypotheses for every sequence in the\n  batch and pass in the number of sequences  batchSize , or only specify one\n  hypothesis per sequence by passing  token  and  state  with first dimension\n   batchSize , and then  onmt.translate.BeamSearcher  will pad with auxiliary\n  hypotheses with scores  -inf  such that each sequence starts with  beamSize \n  hypotheses as in the former case.  Parameters:   token  - tensor of size  (batchSize, vocabSize)  (if start with one initial\n  hypothesis per sequence) or  (batchSize * beamSize, vocabSize)  (if start with\n   beamSize  initial hypotheses per sequence), or a list of such tensors.  state  - an iterable object, where the contained tensors should have the\n  same first dimension as  token .  batchSize  - optional, number of sentences. Only necessary if\n  start with  beamSize  hypotheses per sequence. [ token:size(1) ]   [src]",
            "title": "onmt.Beam(token, state, batchSize)"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamgettokens",
            "text": "Returns:   tokens  - a list of tokens. Note that the start-of-sequence symbols are\n  also included.  tokens[t]  stores the tokens at step  t , which is a tensor\n  of size  batchSize * beamSize .   [src]",
            "title": "onmt.Beam:getTokens()"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamgetstate",
            "text": "Returns:   state  - an abstract iterable object as passed by constructor. Every tensor\n  inside the  state  has first dimension  batchSize * beamSize   [src]",
            "title": "onmt.Beam:getState()"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamgetscores",
            "text": "Returns:   scores  - a flat tensor storing the total scores for each batch. It is of\n  size  batchSize * beamSize .   [src]",
            "title": "onmt.Beam:getScores()"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamgetbackpointer",
            "text": "Returns:   backPointer  - a flat tensor storing the backpointers for each batch. It is\n  of size  batchSize * beamSize   [src]",
            "title": "onmt.Beam:getBackPointer()"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamgetremaining",
            "text": "Returns the number of unfinished sequences. The finished sequences will be\n  removed from batch.  Returns:   remaining  - the number of unfinished sequences.   [src]",
            "title": "onmt.Beam:getRemaining()"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamremaining2origremainingid",
            "text": "Since finished sequences are being removed from the batch, this function\n  provides a way to convert the remaining batch id to the original batch id.  [src]",
            "title": "onmt.Beam:remaining2Orig(remainingId)"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamorig2remainingorigid",
            "text": "Since finished sequences are being removed from the batch, this function\n  provides a way to convert the original batch id to the remaining batch id.  [src]",
            "title": "onmt.Beam:orig2Remaining(origId)"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamsetstatestate",
            "text": "Set state.  [src]",
            "title": "onmt.Beam:setState(state)"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamsetscoresscores",
            "text": "Set scores.  [src]",
            "title": "onmt.Beam:setScores(scores)"
        },
        {
            "location": "/code/translate/onmt+translate+Beam/#onmtbeamsetbackpointerbackpointer",
            "text": "Set backPointer.",
            "title": "onmt.Beam:setBackPointer(backPointer)"
        },
        {
            "location": "/code/translate/onmt+translate+BeamSearcher/",
            "text": "onmt.BeamSearcher\n\n\nClass for managing the internals of the beam search process.\n\n\n  hyp1---hyp1---hyp1 -hyp1\n      \\             /\n  hyp2 \\-hyp2 /-hyp2--hyp2\n             /      \\\n  hyp3---hyp3---hyp3 -hyp3\n  ========================\n\n\n\nTakes care of beams.\n\n\n[src]\n\n\n\n\nonmt.BeamSearcher(advancer)\n\n\nConstructor\n\n\nParameters:\n\n\n\n\nadvancer\n - an \nonmt.translate.Advancer\n object.\n\n\n\n\n[src]\n\n\n\n\nonmt.BeamSearcher:search(beamSize, nBest, preFilterFactor, keepInitial)\n\n\nPerforms beam search.\n\n\nParameters:\n\n\n\n\nbeamSize\n - beam size. [1]\n\n\nnBest\n - the \nnBest\n top hypotheses will be returned after beam search. [1]\n\n\npreFilterFactor\n - optional, set this only if filter is being used. Before\n  applying filters, hypotheses with top \nbeamSize * preFilterFactor\n scores will\n  be considered. If the returned hypotheses voilate filters, then set this to a\n  larger value to consider more. [1]\n\n\nkeepInitial\n - optional, whether return the initial token or not. [false]\n\n\n\n\nReturns: a table \nfinished\n. \nfinished[b][n].score\n, \nfinished[b][n].tokens\n\nand \nfinished[b][n].states\n describe the n-th best hypothesis for b-th sample\nin the batch.",
            "title": "onmt+translate+BeamSearcher"
        },
        {
            "location": "/code/translate/onmt+translate+BeamSearcher/#onmtbeamsearcher",
            "text": "Class for managing the internals of the beam search process.    hyp1---hyp1---hyp1 -hyp1\n      \\             /\n  hyp2 \\-hyp2 /-hyp2--hyp2\n             /      \\\n  hyp3---hyp3---hyp3 -hyp3\n  ========================  Takes care of beams.  [src]",
            "title": "onmt.BeamSearcher"
        },
        {
            "location": "/code/translate/onmt+translate+BeamSearcher/#onmtbeamsearcheradvancer",
            "text": "Constructor  Parameters:   advancer  - an  onmt.translate.Advancer  object.   [src]",
            "title": "onmt.BeamSearcher(advancer)"
        },
        {
            "location": "/code/translate/onmt+translate+BeamSearcher/#onmtbeamsearchersearchbeamsize-nbest-prefilterfactor-keepinitial",
            "text": "Performs beam search.  Parameters:   beamSize  - beam size. [1]  nBest  - the  nBest  top hypotheses will be returned after beam search. [1]  preFilterFactor  - optional, set this only if filter is being used. Before\n  applying filters, hypotheses with top  beamSize * preFilterFactor  scores will\n  be considered. If the returned hypotheses voilate filters, then set this to a\n  larger value to consider more. [1]  keepInitial  - optional, whether return the initial token or not. [false]   Returns: a table  finished .  finished[b][n].score ,  finished[b][n].tokens \nand  finished[b][n].states  describe the n-th best hypothesis for b-th sample\nin the batch.",
            "title": "onmt.BeamSearcher:search(beamSize, nBest, preFilterFactor, keepInitial)"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/",
            "text": "onmt.DecoderAdvancer\n\n\nDecoderAdvancer is an implementation of the interface Advancer for\n  specifyinghow to advance one step in decoder.\n\n\n[src]\n\n\n\n\nonmt.DecoderAdvancer(decoder, batch, context, max_sent_length, max_num_unks, decStates, dicts)\n\n\nConstructor.\n\n\nParameters:\n\n\n\n\ndecoder\n - an \nonmt.Decoder\n object.\n\n\nbatch\n - an \nonmt.data.Batch\n object.\n\n\ncontext\n - encoder output (batch x n x rnnSize).\n\n\nmax_sent_length\n - optional, maximum output sentence length.\n\n\nmax_num_unks\n - optional, maximum number of UNKs.\n\n\ndecStates\n - optional, initial decoder states.\n\n\ndicts\n - optional, dictionary for additional features.\n\n\n\n\n[src]\n\n\n\n\nonmt.DecoderAdvancer:initBeam()\n\n\nReturns an initial beam.\n\n\nReturns:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\n[src]\n\n\n\n\nonmt.DecoderAdvancer:update(beam)\n\n\nUpdates beam states given new tokens.\n\n\nParameters:\n\n\n\n\nbeam\n - beam with updated token list.\n\n\n\n\n[src]\n\n\n\n\nonmt.DecoderAdvancer:expand(beam)\n\n\nExpand function. Expands beam by all possible tokens and returns the\n  scores.\n\n\nParameters:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\nReturns:\n\n\n\n\nscores\n - a 2D tensor of size \n(batchSize * beamSize, numTokens)\n.\n\n\n\n\n[src]\n\n\n\n\nonmt.DecoderAdvancer:isComplete(beam)\n\n\nChecks which hypotheses in the beam are already finished. A hypothesis is\n  complete if i) an onmt.Constants.EOS is encountered, or ii) the length of the\n  sequence is greater than or equal to \nmax_sent_length\n.\n\n\nParameters:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\nReturns: a binary flat tensor of size \n(batchSize * beamSize)\n, indicating\n  which hypotheses are finished.\n\n\n[src]\n\n\n\n\nonmt.DecoderAdvancer:filter(beam)\n\n\nChecks which hypotheses in the beam shall be pruned. We disallow empty\n predictions, as well as predictions with more UNKs than \nmax_num_unks\n.\n\n\nParameters:\n\n\n\n\nbeam\n - an \nonmt.translate.Beam\n object.\n\n\n\n\nReturns: a binary flat tensor of size \n(batchSize * beamSize)\n, indicating\n  which beams shall be pruned.",
            "title": "onmt+translate+DecoderAdvancer"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/#onmtdecoderadvancer",
            "text": "DecoderAdvancer is an implementation of the interface Advancer for\n  specifyinghow to advance one step in decoder.  [src]",
            "title": "onmt.DecoderAdvancer"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/#onmtdecoderadvancerdecoder-batch-context-max_sent_length-max_num_unks-decstates-dicts",
            "text": "Constructor.  Parameters:   decoder  - an  onmt.Decoder  object.  batch  - an  onmt.data.Batch  object.  context  - encoder output (batch x n x rnnSize).  max_sent_length  - optional, maximum output sentence length.  max_num_unks  - optional, maximum number of UNKs.  decStates  - optional, initial decoder states.  dicts  - optional, dictionary for additional features.   [src]",
            "title": "onmt.DecoderAdvancer(decoder, batch, context, max_sent_length, max_num_unks, decStates, dicts)"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/#onmtdecoderadvancerinitbeam",
            "text": "Returns an initial beam.  Returns:   beam  - an  onmt.translate.Beam  object.   [src]",
            "title": "onmt.DecoderAdvancer:initBeam()"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/#onmtdecoderadvancerupdatebeam",
            "text": "Updates beam states given new tokens.  Parameters:   beam  - beam with updated token list.   [src]",
            "title": "onmt.DecoderAdvancer:update(beam)"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/#onmtdecoderadvancerexpandbeam",
            "text": "Expand function. Expands beam by all possible tokens and returns the\n  scores.  Parameters:   beam  - an  onmt.translate.Beam  object.   Returns:   scores  - a 2D tensor of size  (batchSize * beamSize, numTokens) .   [src]",
            "title": "onmt.DecoderAdvancer:expand(beam)"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/#onmtdecoderadvanceriscompletebeam",
            "text": "Checks which hypotheses in the beam are already finished. A hypothesis is\n  complete if i) an onmt.Constants.EOS is encountered, or ii) the length of the\n  sequence is greater than or equal to  max_sent_length .  Parameters:   beam  - an  onmt.translate.Beam  object.   Returns: a binary flat tensor of size  (batchSize * beamSize) , indicating\n  which hypotheses are finished.  [src]",
            "title": "onmt.DecoderAdvancer:isComplete(beam)"
        },
        {
            "location": "/code/translate/onmt+translate+DecoderAdvancer/#onmtdecoderadvancerfilterbeam",
            "text": "Checks which hypotheses in the beam shall be pruned. We disallow empty\n predictions, as well as predictions with more UNKs than  max_num_unks .  Parameters:   beam  - an  onmt.translate.Beam  object.   Returns: a binary flat tensor of size  (batchSize * beamSize) , indicating\n  which beams shall be pruned.",
            "title": "onmt.DecoderAdvancer:filter(beam)"
        },
        {
            "location": "/code/translate/onmt+translate+PhraseTable/",
            "text": "onmt.PhraseTable\n\n\nParse and lookup a words from a phrase table.\n\n\n[src]\n\n\n\n\nonmt.PhraseTable:lookup(word)\n\n\nReturn the phrase table match for \nword\n. \n\n\n[src]\n\n\n\n\nonmt.PhraseTable:contains(word)\n\n\nReturn true if the phrase table contains the source word \nword\n. \n\n\nUndocumented methods\n\n\n\n * \nonmt.PhraseTable(filePath)",
            "title": "onmt+translate+PhraseTable"
        },
        {
            "location": "/code/translate/onmt+translate+PhraseTable/#onmtphrasetable",
            "text": "Parse and lookup a words from a phrase table.  [src]",
            "title": "onmt.PhraseTable"
        },
        {
            "location": "/code/translate/onmt+translate+PhraseTable/#onmtphrasetablelookupword",
            "text": "Return the phrase table match for  word .   [src]",
            "title": "onmt.PhraseTable:lookup(word)"
        },
        {
            "location": "/code/translate/onmt+translate+PhraseTable/#onmtphrasetablecontainsword",
            "text": "Return true if the phrase table contains the source word  word .",
            "title": "onmt.PhraseTable:contains(word)"
        },
        {
            "location": "/code/translate/onmt+translate+PhraseTable/#undocumented-methods",
            "text": "*  onmt.PhraseTable(filePath)",
            "title": "Undocumented methods"
        },
        {
            "location": "/code/translate/onmt+translate+Translator/",
            "text": "onmt.Translator\n\n\n[src]\n\n\n\n\nonmt.Translator:translate(src, gold)\n\n\nTranslate a batch of source sequences.\n\n\nParameters:\n\n\n\n\nsrc\n - a batch of tables containing:\n\n\nwords\n: the table of source words\n\n\nfeatures\n: the table of feaures sequences (\nsrc.features[i][j]\n is the value of the ith feature of the jth token)\n\n\n\n\n\n\ngold\n - gold data to compute confidence score (same format as \nsrc\n)\n\n\n\n\nReturns:\n\n\n\n\nresults\n - a batch of tables containing:\n\n\ngoldScore\n: if \ngold\n was given, this is the confidence score\n\n\npreds\n: an array of \nopt.n_best\n tables containing:\n\n\nwords\n: the table of target words\n\n\nfeatures\n: the table of target features sequences\n\n\nattention\n: the attention vectors of each target word over the source words\n\n\nscore\n: the confidence score of the prediction\n\n\n\n\n\n\n\n\nUndocumented methods\n\n\n\n * \nonmt.Translator.declareOpts(cmd)\n\n\n\n * \nonmt.Translator(args)\n\n\n\n * \nonmt.Translator:buildInput(tokens)\n\n\n\n * \nonmt.Translator:buildOutput(data)\n\n\n\n * \nonmt.Translator:buildData(src, gold)\n\n\n\n * \nonmt.Translator:buildTargetWords(pred, src, attn)\n\n\n\n * \nonmt.Translator:buildTargetFeatures(predFeats)\n\n\n\n * \nonmt.Translator:translateBatch(batch)",
            "title": "onmt+translate+Translator"
        },
        {
            "location": "/code/translate/onmt+translate+Translator/#onmttranslator",
            "text": "[src]",
            "title": "onmt.Translator"
        },
        {
            "location": "/code/translate/onmt+translate+Translator/#onmttranslatortranslatesrc-gold",
            "text": "Translate a batch of source sequences.  Parameters:   src  - a batch of tables containing:  words : the table of source words  features : the table of feaures sequences ( src.features[i][j]  is the value of the ith feature of the jth token)    gold  - gold data to compute confidence score (same format as  src )   Returns:   results  - a batch of tables containing:  goldScore : if  gold  was given, this is the confidence score  preds : an array of  opt.n_best  tables containing:  words : the table of target words  features : the table of target features sequences  attention : the attention vectors of each target word over the source words  score : the confidence score of the prediction",
            "title": "onmt.Translator:translate(src, gold)"
        },
        {
            "location": "/code/translate/onmt+translate+Translator/#undocumented-methods",
            "text": "*  onmt.Translator.declareOpts(cmd)  \n *  onmt.Translator(args)  \n *  onmt.Translator:buildInput(tokens)  \n *  onmt.Translator:buildOutput(data)  \n *  onmt.Translator:buildData(src, gold)  \n *  onmt.Translator:buildTargetWords(pred, src, attn)  \n *  onmt.Translator:buildTargetFeatures(predFeats)  \n *  onmt.Translator:translateBatch(batch)",
            "title": "Undocumented methods"
        },
        {
            "location": "/details/preprocess/",
            "text": "preprocess.lua\n\n\n\n\n-h\n: This help. [false]\n\n\n-md\n: Dump help in Markdown format. [false]\n\n\n-config\n: Read options from config file. []\n\n\n-save_config\n: Save options from config file. []\n\n\n\n\nPreprocess options\n\n\n\n\n-data_type\n: (bitext, monotext) Type of text to preprocess. Use 'monotext' for monolingual text. This option impacts all options choices. [bitext]\n\n\n-save_data\n: Output file for the prepared data. []\n\n\n\n\nPreprocess options\n\n\n\n\n-train_src\n: Path to the training source data. []\n\n\n-train_tgt\n: Path to the training target data. []\n\n\n-valid_src\n: Path to the validation source data. []\n\n\n-valid_tgt\n: Path to the validation target data. []\n\n\n-src_vocab\n: Path to an existing source vocabulary. []\n\n\n-tgt_vocab\n: Path to an existing target vocabulary. []\n\n\n-src_vocab_size\n: Comma-separated list of source vocabularies size: word[,feat1,feat2,...]. [50000]\n\n\n-tgt_vocab_size\n: Comma-separated list of target vocabularies size: word[,feat1,feat2,...]. [50000]\n\n\n-src_seq_length\n: Maximum source sequence length. [50]\n\n\n-tgt_seq_length\n: Maximum target sequence length. [50]\n\n\n-features_vocabs_prefix\n: Path prefix to existing features vocabularies. []\n\n\n-shuffle\n: If 1, shuffle data. [1]\n\n\n\n\nOther options\n\n\n\n\n-seed\n: Random seed. [3425]\n\n\n-report_every\n: Report status every this many sentences. [100000]\n\n\n-log_file\n: Outputs logs to a file under this path instead of stdout. []\n\n\n-disable_logs\n: When activated, output nothing. [false]\n\n\n-log_level\n: (DEBUG, INFO, WARNING, ERROR) Outputs logs at this level and above. [INFO]",
            "title": "Preprocess"
        },
        {
            "location": "/details/preprocess/#preprocesslua",
            "text": "-h : This help. [false]  -md : Dump help in Markdown format. [false]  -config : Read options from config file. []  -save_config : Save options from config file. []",
            "title": "preprocess.lua"
        },
        {
            "location": "/details/preprocess/#preprocess-options",
            "text": "-data_type : (bitext, monotext) Type of text to preprocess. Use 'monotext' for monolingual text. This option impacts all options choices. [bitext]  -save_data : Output file for the prepared data. []",
            "title": "Preprocess options"
        },
        {
            "location": "/details/preprocess/#preprocess-options_1",
            "text": "-train_src : Path to the training source data. []  -train_tgt : Path to the training target data. []  -valid_src : Path to the validation source data. []  -valid_tgt : Path to the validation target data. []  -src_vocab : Path to an existing source vocabulary. []  -tgt_vocab : Path to an existing target vocabulary. []  -src_vocab_size : Comma-separated list of source vocabularies size: word[,feat1,feat2,...]. [50000]  -tgt_vocab_size : Comma-separated list of target vocabularies size: word[,feat1,feat2,...]. [50000]  -src_seq_length : Maximum source sequence length. [50]  -tgt_seq_length : Maximum target sequence length. [50]  -features_vocabs_prefix : Path prefix to existing features vocabularies. []  -shuffle : If 1, shuffle data. [1]",
            "title": "Preprocess options"
        },
        {
            "location": "/details/preprocess/#other-options",
            "text": "-seed : Random seed. [3425]  -report_every : Report status every this many sentences. [100000]  -log_file : Outputs logs to a file under this path instead of stdout. []  -disable_logs : When activated, output nothing. [false]  -log_level : (DEBUG, INFO, WARNING, ERROR) Outputs logs at this level and above. [INFO]",
            "title": "Other options"
        },
        {
            "location": "/details/train/",
            "text": "train.lua\n\n\n\n\n-h\n: This help. [false]\n\n\n-md\n: Dump help in Markdown format. [false]\n\n\n-config\n: Read options from config file. []\n\n\n-save_config\n: Save options from config file. []\n\n\n\n\nData options\n\n\n\n\n-data\n: Path to the training *-train.t7 file from preprocess.lua []\n\n\n-save_model\n: Model filename (the model will be saved as \n_epochN_PPL.t7 where PPL is the validation perplexity []\n\n\n-model_type\n: (lm, seq2seq) Type of the model to train. This option impacts all options choices [seq2seq]\n\n\n-param_init\n: Parameters are initialized over uniform distribution with support (-param_init, param_init) [0.1]\n\n\n\n\nSequence to Sequence with Attention options\n\n\n\n\n-layers\n: Number of layers in the RNN encoder/decoder [2]\n\n\n-rnn_size\n: Size of RNN hidden states [500]\n\n\n-rnn_type\n: (LSTM, GRU) Type of RNN cell [LSTM]\n\n\n-word_vec_size\n: Common word embedding size. If set, this overrides -src_word_vec_size and -tgt_word_vec_size. [0]\n\n\n-src_word_vec_size\n: Comma-separated list of source embedding sizes: word[,feat1,feat2,...]. [500]\n\n\n-tgt_word_vec_size\n: Comma-separated list of target embedding sizes: word[,feat1,feat2,...]. [500]\n\n\n-feat_merge\n: (concat, sum) Merge action for the features embeddings [concat]\n\n\n-feat_vec_exponent\n: When features embedding sizes are not set and using -feat_merge concat, their dimension will be set to N^exponent where N is the number of values the feature takes. [0.7]\n\n\n-feat_vec_size\n: When features embedding sizes are not set and using -feat_merge sum, this is the common embedding size of the features [20]\n\n\n-input_feed\n: (0, 1) Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder. [1]\n\n\n-residual\n: Add residual connections between RNN layers. [false]\n\n\n-brnn\n: Use a bidirectional encoder [false]\n\n\n-brnn_merge\n: (concat, sum) Merge action for the bidirectional hidden states [sum]\n\n\n-pre_word_vecs_enc\n: If a valid path is specified, then this will load pretrained word embeddings on the encoder side. See README for specific formatting instructions. []\n\n\n-pre_word_vecs_dec\n: If a valid path is specified, then this will load pretrained word embeddings on the decoder side. See README for specific formatting instructions. []\n\n\n-fix_word_vecs_enc\n: Fix word embeddings on the encoder side [false]\n\n\n-fix_word_vecs_dec\n: Fix word embeddings on the decoder side [false]\n\n\n-dropout\n: Dropout probability. Dropout is applied between vertical LSTM stacks. [0.3]\n\n\n\n\nOptimization options\n\n\n\n\n-max_batch_size\n: Maximum batch size [64]\n\n\n-optim\n: (sgd, adagrad, adadelta, adam) Optimization method. [sgd]\n\n\n-learning_rate\n: Starting learning rate. If adagrad or adam is used, then this is the global learning rate. Recommended settings are: sgd = 1, adagrad = 0.1, adam = 0.0002 [1]\n\n\n-max_grad_norm\n: If the norm of the gradient vector exceeds this renormalize it to have the norm equal to max_grad_norm [5]\n\n\n-learning_rate_decay\n: Decay learning rate by this much if (i) perplexity does not decrease on the validation set or (ii) epoch has gone past the start_decay_at_limit [0.5]\n\n\n-start_decay_at\n: Start decay after this epoch [9]\n\n\n\n\nTrainer options\n\n\n\n\n-save_every\n: Save intermediate models every this many iterations within an epoch. If = 0, will not save models within an epoch.  [0]\n\n\n-report_every\n: Print stats every this many iterations within an epoch. [50]\n\n\n-async_parallel\n: Use asynchronous parallelism training. [false]\n\n\n-async_parallel_minbatch\n: For async parallel computing, minimal number of batches before being parallel. [1000]\n\n\n-start_iteration\n: If loading from a checkpoint, the iteration from which to start [1]\n\n\n-end_epoch\n: The final epoch of the training [13]\n\n\n-start_epoch\n: If loading from a checkpoint, the epoch from which to start [1]\n\n\n-curriculum\n: For this many epochs, order the minibatches based on source sequence length. Sometimes setting this to 1 will increase convergence speed. [0]\n\n\n\n\nCheckpoint options\n\n\n\n\n-train_from\n: If training from a checkpoint then this is the path to the pretrained model. []\n\n\n-continue\n: If training from a checkpoint, whether to continue the training in the same configuration or not. [false]\n\n\n\n\nOther options\n\n\n\n\n-gpuid\n: List of comma-separated GPU identifiers (1-indexed). CPU is used when set to 0. [0]\n\n\n-fallback_to_cpu\n: If GPU can't be use, rollback on the CPU. [false]\n\n\n-no_nccl\n: Disable usage of nccl in parallel mode. [false]\n\n\n-disable_mem_optimization\n: Disable sharing internal of internal buffers between clones - which is in general safe, except if you want to look inside clones for visualization purpose for instance. [false]\n\n\n-log_file\n: Outputs logs to a file under this path instead of stdout. []\n\n\n-disable_logs\n: When activated, output nothing. [false]\n\n\n-log_level\n: (DEBUG, INFO, WARNING, ERROR) Outputs logs at this level and above. [INFO]\n\n\n-profiler\n: Generate profiling logs. [false]\n\n\n-seed\n: Seed for random initialization [3435]",
            "title": "Train"
        },
        {
            "location": "/details/train/#trainlua",
            "text": "-h : This help. [false]  -md : Dump help in Markdown format. [false]  -config : Read options from config file. []  -save_config : Save options from config file. []",
            "title": "train.lua"
        },
        {
            "location": "/details/train/#data-options",
            "text": "-data : Path to the training *-train.t7 file from preprocess.lua []  -save_model : Model filename (the model will be saved as  _epochN_PPL.t7 where PPL is the validation perplexity []  -model_type : (lm, seq2seq) Type of the model to train. This option impacts all options choices [seq2seq]  -param_init : Parameters are initialized over uniform distribution with support (-param_init, param_init) [0.1]",
            "title": "Data options"
        },
        {
            "location": "/details/train/#sequence-to-sequence-with-attention-options",
            "text": "-layers : Number of layers in the RNN encoder/decoder [2]  -rnn_size : Size of RNN hidden states [500]  -rnn_type : (LSTM, GRU) Type of RNN cell [LSTM]  -word_vec_size : Common word embedding size. If set, this overrides -src_word_vec_size and -tgt_word_vec_size. [0]  -src_word_vec_size : Comma-separated list of source embedding sizes: word[,feat1,feat2,...]. [500]  -tgt_word_vec_size : Comma-separated list of target embedding sizes: word[,feat1,feat2,...]. [500]  -feat_merge : (concat, sum) Merge action for the features embeddings [concat]  -feat_vec_exponent : When features embedding sizes are not set and using -feat_merge concat, their dimension will be set to N^exponent where N is the number of values the feature takes. [0.7]  -feat_vec_size : When features embedding sizes are not set and using -feat_merge sum, this is the common embedding size of the features [20]  -input_feed : (0, 1) Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder. [1]  -residual : Add residual connections between RNN layers. [false]  -brnn : Use a bidirectional encoder [false]  -brnn_merge : (concat, sum) Merge action for the bidirectional hidden states [sum]  -pre_word_vecs_enc : If a valid path is specified, then this will load pretrained word embeddings on the encoder side. See README for specific formatting instructions. []  -pre_word_vecs_dec : If a valid path is specified, then this will load pretrained word embeddings on the decoder side. See README for specific formatting instructions. []  -fix_word_vecs_enc : Fix word embeddings on the encoder side [false]  -fix_word_vecs_dec : Fix word embeddings on the decoder side [false]  -dropout : Dropout probability. Dropout is applied between vertical LSTM stacks. [0.3]",
            "title": "Sequence to Sequence with Attention options"
        },
        {
            "location": "/details/train/#optimization-options",
            "text": "-max_batch_size : Maximum batch size [64]  -optim : (sgd, adagrad, adadelta, adam) Optimization method. [sgd]  -learning_rate : Starting learning rate. If adagrad or adam is used, then this is the global learning rate. Recommended settings are: sgd = 1, adagrad = 0.1, adam = 0.0002 [1]  -max_grad_norm : If the norm of the gradient vector exceeds this renormalize it to have the norm equal to max_grad_norm [5]  -learning_rate_decay : Decay learning rate by this much if (i) perplexity does not decrease on the validation set or (ii) epoch has gone past the start_decay_at_limit [0.5]  -start_decay_at : Start decay after this epoch [9]",
            "title": "Optimization options"
        },
        {
            "location": "/details/train/#trainer-options",
            "text": "-save_every : Save intermediate models every this many iterations within an epoch. If = 0, will not save models within an epoch.  [0]  -report_every : Print stats every this many iterations within an epoch. [50]  -async_parallel : Use asynchronous parallelism training. [false]  -async_parallel_minbatch : For async parallel computing, minimal number of batches before being parallel. [1000]  -start_iteration : If loading from a checkpoint, the iteration from which to start [1]  -end_epoch : The final epoch of the training [13]  -start_epoch : If loading from a checkpoint, the epoch from which to start [1]  -curriculum : For this many epochs, order the minibatches based on source sequence length. Sometimes setting this to 1 will increase convergence speed. [0]",
            "title": "Trainer options"
        },
        {
            "location": "/details/train/#checkpoint-options",
            "text": "-train_from : If training from a checkpoint then this is the path to the pretrained model. []  -continue : If training from a checkpoint, whether to continue the training in the same configuration or not. [false]",
            "title": "Checkpoint options"
        },
        {
            "location": "/details/train/#other-options",
            "text": "-gpuid : List of comma-separated GPU identifiers (1-indexed). CPU is used when set to 0. [0]  -fallback_to_cpu : If GPU can't be use, rollback on the CPU. [false]  -no_nccl : Disable usage of nccl in parallel mode. [false]  -disable_mem_optimization : Disable sharing internal of internal buffers between clones - which is in general safe, except if you want to look inside clones for visualization purpose for instance. [false]  -log_file : Outputs logs to a file under this path instead of stdout. []  -disable_logs : When activated, output nothing. [false]  -log_level : (DEBUG, INFO, WARNING, ERROR) Outputs logs at this level and above. [INFO]  -profiler : Generate profiling logs. [false]  -seed : Seed for random initialization [3435]",
            "title": "Other options"
        },
        {
            "location": "/details/translate/",
            "text": "translate.lua\n\n\n\n\n-h\n: This help. [false]\n\n\n-md\n: Dump help in Markdown format. [false]\n\n\n-config\n: Read options from config file. []\n\n\n-save_config\n: Save options from config file. []\n\n\n\n\nData options\n\n\n\n\n-src\n: Source sequence to decode (one line per sequence) []\n\n\n-tgt\n: True target sequence (optional) []\n\n\n-output\n: Path to output the predictions (each line will be the decoded sequence) [pred.txt]\n\n\n\n\nTranslator options\n\n\n\n\n-model\n: Path to model .t7 file []\n\n\n-beam_size\n: Beam size [5]\n\n\n-batch_size\n: Batch size [30]\n\n\n-max_sent_length\n: Maximum output sentence length. [250]\n\n\n-replace_unk\n: Replace the generated UNK tokens with the source token that had the highest attention weight. If phrase_table is provided, it will lookup the identified source token and give the corresponding target token. If it is not provided (or the identified source token does not exist in the table) then it will copy the source token [false]\n\n\n-phrase_table\n: Path to source-target dictionary to replace UNK tokens. See README.md for the format this file should be in []\n\n\n-n_best\n: If \n 1, it will also output an n_best list of decoded sentences [1]\n\n\n-max_num_unks\n: All sequences with more unks than this will be ignored during beam search [inf]\n\n\n-pre_filter_factor\n: Optional, set this only if filter is being used. Before applying filters, hypotheses with top \nbeamSize * preFilterFactor\n scores will be considered. If the returned hypotheses voilate filters, then set this to a larger value to consider more. [1]\n\n\n\n\nOther options\n\n\n\n\n-time\n: Measure batch translation time [false]\n\n\n-gpuid\n: List of comma-separated GPU identifiers (1-indexed). CPU is used when set to 0. [0]\n\n\n-fallback_to_cpu\n: If GPU can't be use, rollback on the CPU. [false]\n\n\n-no_nccl\n: Disable usage of nccl in parallel mode. [false]\n\n\n-log_file\n: Outputs logs to a file under this path instead of stdout. []\n\n\n-disable_logs\n: When activated, output nothing. [false]\n\n\n-log_level\n: (DEBUG, INFO, WARNING, ERROR) Outputs logs at this level and above. [INFO]",
            "title": "Translate"
        },
        {
            "location": "/details/translate/#translatelua",
            "text": "-h : This help. [false]  -md : Dump help in Markdown format. [false]  -config : Read options from config file. []  -save_config : Save options from config file. []",
            "title": "translate.lua"
        },
        {
            "location": "/details/translate/#data-options",
            "text": "-src : Source sequence to decode (one line per sequence) []  -tgt : True target sequence (optional) []  -output : Path to output the predictions (each line will be the decoded sequence) [pred.txt]",
            "title": "Data options"
        },
        {
            "location": "/details/translate/#translator-options",
            "text": "-model : Path to model .t7 file []  -beam_size : Beam size [5]  -batch_size : Batch size [30]  -max_sent_length : Maximum output sentence length. [250]  -replace_unk : Replace the generated UNK tokens with the source token that had the highest attention weight. If phrase_table is provided, it will lookup the identified source token and give the corresponding target token. If it is not provided (or the identified source token does not exist in the table) then it will copy the source token [false]  -phrase_table : Path to source-target dictionary to replace UNK tokens. See README.md for the format this file should be in []  -n_best : If   1, it will also output an n_best list of decoded sentences [1]  -max_num_unks : All sequences with more unks than this will be ignored during beam search [inf]  -pre_filter_factor : Optional, set this only if filter is being used. Before applying filters, hypotheses with top  beamSize * preFilterFactor  scores will be considered. If the returned hypotheses voilate filters, then set this to a larger value to consider more. [1]",
            "title": "Translator options"
        },
        {
            "location": "/details/translate/#other-options",
            "text": "-time : Measure batch translation time [false]  -gpuid : List of comma-separated GPU identifiers (1-indexed). CPU is used when set to 0. [0]  -fallback_to_cpu : If GPU can't be use, rollback on the CPU. [false]  -no_nccl : Disable usage of nccl in parallel mode. [false]  -log_file : Outputs logs to a file under this path instead of stdout. []  -disable_logs : When activated, output nothing. [false]  -log_level : (DEBUG, INFO, WARNING, ERROR) Outputs logs at this level and above. [INFO]",
            "title": "Other options"
        }
    ]
}