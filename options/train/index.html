
<!DOCTYPE html>
<html class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="shortcut icon" href="../../assets/images/favicon.png">
      
      <meta name="generator" content="mkdocs-0.16.3, mkdocs-material-1.5.5">
    
    
      
        <title>train.lua - OpenNMT</title>
      
    
    
      <script src="../../assets/javascripts/modernizr-56ade86843.js"></script>
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/application-b1a1975878.css">
      
    
    
      
        
        
        
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,400,400i,700|Roboto+Mono">
        <style>body,input{font-family:"Roboto","Helvetica Neue",Helvetica,Arial,sans-serif}code,kbd,pre{font-family:"Roboto Mono","Courier New",Courier,monospace}</style>
      
      <link rel="stylesheet" href="https://fonts.googleapis.com/icon?family=Material+Icons">
    
    
      <link rel="stylesheet" href="../../css/extra.css">
    
      <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.4/css/select2.min.css">
    
    
  </head>
  
  
  
  
    <body>
  
    <svg class="md-svg">
      <defs>
        
        
          <svg xmlns="http://www.w3.org/2000/svg" width="416" height="448" viewBox="0 0 416 448" id="github"><path fill="currentColor" d="M160 304q0 10-3.125 20.5t-10.75 19T128 352t-18.125-8.5-10.75-19T96 304t3.125-20.5 10.75-19T128 256t18.125 8.5 10.75 19T160 304zm160 0q0 10-3.125 20.5t-10.75 19T288 352t-18.125-8.5-10.75-19T256 304t3.125-20.5 10.75-19T288 256t18.125 8.5 10.75 19T320 304zm40 0q0-30-17.25-51T296 232q-10.25 0-48.75 5.25Q229.5 240 208 240t-39.25-2.75Q130.75 232 120 232q-29.5 0-46.75 21T56 304q0 22 8 38.375t20.25 25.75 30.5 15 35 7.375 37.25 1.75h42q20.5 0 37.25-1.75t35-7.375 30.5-15 20.25-25.75T360 304zm56-44q0 51.75-15.25 82.75-9.5 19.25-26.375 33.25t-35.25 21.5-42.5 11.875-42.875 5.5T212 416q-19.5 0-35.5-.75t-36.875-3.125-38.125-7.5-34.25-12.875T37 371.5t-21.5-28.75Q0 312 0 260q0-59.25 34-99-6.75-20.5-6.75-42.5 0-29 12.75-54.5 27 0 47.5 9.875t47.25 30.875Q171.5 96 212 96q37 0 70 8 26.25-20.5 46.75-30.25T376 64q12.75 25.5 12.75 54.5 0 21.75-6.75 42 34 40 34 99.5z"/></svg>
        
      </defs>
    </svg>
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="drawer">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="search">
    <label class="md-overlay" data-md-component="overlay" for="drawer"></label>
    
      <header class="md-header" data-md-component="header">
  <nav class="md-header-nav md-grid">
    <div class="md-flex">
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <a href="../.." title="OpenNMT" class="md-logo md-header-nav__button">
            <img src="../../img/logo-alpha.png" width="24" height="24">
          </a>
        
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <label class="md-icon md-icon--menu md-header-nav__button" for="drawer"></label>
      </div>
      <div class="md-flex__cell md-flex__cell--stretch">
        <span class="md-flex__ellipsis md-header-nav__title">
          
            
              
                <span class="md-header-nav__parent">
                  Reference: Options
                </span>
              
            
            train.lua
          
        </span>
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        
          <label class="md-icon md-icon--search md-header-nav__button" for="search"></label>
          
<div class="md-search" data-md-component="search">
  <div class="md-search__overlay"></div>
  <div class="md-search__inner">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" required placeholder="Search" accesskey="s" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="query">
      <label class="md-icon md-search__icon" for="search"></label>
      <button type="reset" class="md-icon md-search__icon" data-md-component="reset">close</button>
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="result">
          <div class="md-search-result__meta" data-md-lang-result-none="No matching documents" data-md-lang-result-one="1 matching document" data-md-lang-result-other="# matching documents">
            Type to start searching
          </div>
          <ol class="md-search-result__list"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
        
      </div>
      <div class="md-flex__cell md-flex__cell--shrink">
        <div class="md-header-nav__source">
          
            


  


  <a href="https://github.com/OpenNMT/OpenNMT" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      OpenNMT/OpenNMT
    </div>
  </a>

          
        </div>
      </div>
    </div>
  </nav>
</header>
    
    <div class="md-container">
      
      
      <main class="md-main">
        <div class="md-main__inner md-grid" data-md-component="container">
          
            
              <div class="md-sidebar md-sidebar--primary" data-md-component="navigation">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    <nav class="md-nav md-nav--primary" data-md-level="0">
  <label class="md-nav__title md-nav__title--site" for="drawer">
    
      <i class="md-logo md-nav__button">
        <img src="../../img/logo-alpha.png">
      </i>
    
    OpenNMT
  </label>
  
    <div class="md-nav__source">
      


  


  <a href="https://github.com/OpenNMT/OpenNMT" title="Go to repository" class="md-source" data-md-source="github">
    
      <div class="md-source__icon">
        <svg viewBox="0 0 24 24" width="24" height="24">
          <use xlink:href="#github" width="24" height="24"></use>
        </svg>
      </div>
    
    <div class="md-source__repository">
      OpenNMT/OpenNMT
    </div>
  </a>

    </div>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      


  <li class="md-nav__item">
    <a href="../.." title="Overview" class="md-nav__link">
      Overview
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../installation/" title="Installation" class="md-nav__link">
      Installation
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../quickstart/" title="Quickstart" class="md-nav__link">
      Quickstart
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../applications/" title="Applications" class="md-nav__link">
      Applications
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-5" type="checkbox" id="nav-5">
    
    <label class="md-nav__link" for="nav-5">
      Data
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-5">
        Data
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../data/preparation/" title="Preparation" class="md-nav__link">
      Preparation
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../data/word_features/" title="Word features" class="md-nav__link">
      Word features
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-6" type="checkbox" id="nav-6">
    
    <label class="md-nav__link" for="nav-6">
      Training
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-6">
        Training
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/models/" title="Models" class="md-nav__link">
      Models
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/embeddings/" title="Embeddings" class="md-nav__link">
      Embeddings
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/logs/" title="Logs" class="md-nav__link">
      Logs
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/multi_gpu/" title="Multi GPU" class="md-nav__link">
      Multi GPU
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/retraining/" title="Retraining" class="md-nav__link">
      Retraining
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/regularization/" title="Regularization" class="md-nav__link">
      Regularization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/decay/" title="Decay strategies" class="md-nav__link">
      Decay strategies
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../training/sampling/" title="Data sampling" class="md-nav__link">
      Data sampling
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-7" type="checkbox" id="nav-7">
    
    <label class="md-nav__link" for="nav-7">
      Translation
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-7">
        Translation
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../translation/inference/" title="Inference" class="md-nav__link">
      Inference
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../translation/beam_search/" title="Beam search" class="md-nav__link">
      Beam search
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../translation/unknowns/" title="Unknown words" class="md-nav__link">
      Unknown words
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-8" type="checkbox" id="nav-8">
    
    <label class="md-nav__link" for="nav-8">
      Tools
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-8">
        Tools
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../../tools/tokenization/" title="Tokenization" class="md-nav__link">
      Tokenization
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../tools/scorer/" title="Scorer" class="md-nav__link">
      Scorer
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../../tools/servers/" title="Servers" class="md-nav__link">
      Servers
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      

  


  <li class="md-nav__item md-nav__item--active md-nav__item--nested">
    
      <input class="md-toggle md-nav__toggle" data-md-toggle="nav-9" type="checkbox" id="nav-9" checked>
    
    <label class="md-nav__link" for="nav-9">
      Reference: Options
    </label>
    <nav class="md-nav" data-md-component="collapsible" data-md-level="1">
      <label class="md-nav__title" for="nav-9">
        Reference: Options
      </label>
      <ul class="md-nav__list" data-md-scrollfix>
        
        
          
          
          


  <li class="md-nav__item">
    <a href="../usage/" title="Scripts usage" class="md-nav__link">
      Scripts usage
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../preprocess/" title="preprocess.lua" class="md-nav__link">
      preprocess.lua
    </a>
  </li>

        
          
          
          

  


  <li class="md-nav__item md-nav__item--active">
    
    <input class="md-toggle md-nav__toggle" data-md-toggle="toc" type="checkbox" id="toc">
    
    
      <label class="md-nav__link md-nav__link--active" for="toc">
        train.lua
      </label>
    
    <a href="./" title="train.lua" class="md-nav__link md-nav__link--active">
      train.lua
    </a>
    
      
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#data-options" title="Data options" class="md-nav__link">
    Data options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampled-dataset-options" title="Sampled dataset options" class="md-nav__link">
    Sampled dataset options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-options_1" title="Data options" class="md-nav__link">
    Data options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenizer-options" title="Tokenizer options" class="md-nav__link">
    Tokenizer options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampled-vocabulary-options" title="Sampled Vocabulary options" class="md-nav__link">
    Sampled Vocabulary options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-options" title="Model options" class="md-nav__link">
    Model options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-to-sequence-with-attention-options" title="Sequence to Sequence with Attention options" class="md-nav__link">
    Sequence to Sequence with Attention options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#global-attention-model-options" title="Global Attention Model options" class="md-nav__link">
    Global Attention Model options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-options" title="Trainer options" class="md-nav__link">
    Trainer options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimization-options" title="Optimization options" class="md-nav__link">
    Optimization options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#saver-options" title="Saver options" class="md-nav__link">
    Saver options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#translator-options" title="Translator options" class="md-nav__link">
    Translator options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#crayon-options" title="Crayon options" class="md-nav__link">
    Crayon options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cuda-options" title="Cuda options" class="md-nav__link">
    Cuda options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logger-options" title="Logger options" class="md-nav__link">
    Logger options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-options" title="Other options" class="md-nav__link">
    Other options
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
    
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../translate/" title="translate.lua" class="md-nav__link">
      translate.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tag/" title="tag.lua" class="md-nav__link">
      tag.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../lm/" title="lm.lua" class="md-nav__link">
      lm.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../build_vocab/" title="tools/build_vocab.lua" class="md-nav__link">
      tools/build_vocab.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../release_model/" title="tools/release_model.lua" class="md-nav__link">
      tools/release_model.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../tokenize/" title="tools/tokenize.lua" class="md-nav__link">
      tools/tokenize.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../learn_bpe/" title="tools/learn_bpe.lua" class="md-nav__link">
      tools/learn_bpe.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../server/" title="tools/translation_server.lua" class="md-nav__link">
      tools/translation_server.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../rest_server/" title="tools/rest_translation_server.lua" class="md-nav__link">
      tools/rest_translation_server.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../embeddings/" title="tools/embeddings.lua" class="md-nav__link">
      tools/embeddings.lua
    </a>
  </li>

        
          
          
          


  <li class="md-nav__item">
    <a href="../average_models/" title="tools/average_models.lua" class="md-nav__link">
      tools/average_models.lua
    </a>
  </li>

        
      </ul>
    </nav>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../lua_python_comparison/" title="Lua and Python OpenNMT" class="md-nav__link">
      Lua and Python OpenNMT
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../references/" title="References" class="md-nav__link">
      References
    </a>
  </li>

    
      
      
      


  <li class="md-nav__item">
    <a href="../../issues/" title="Common issues" class="md-nav__link">
      Common issues
    </a>
  </li>

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              <div class="md-sidebar md-sidebar--secondary" data-md-component="toc">
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    
<nav class="md-nav md-nav--secondary">
  
  
  
    <label class="md-nav__title" for="toc">Table of contents</label>
    <ul class="md-nav__list" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#data-options" title="Data options" class="md-nav__link">
    Data options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampled-dataset-options" title="Sampled dataset options" class="md-nav__link">
    Sampled dataset options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#data-options_1" title="Data options" class="md-nav__link">
    Data options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#tokenizer-options" title="Tokenizer options" class="md-nav__link">
    Tokenizer options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sampled-vocabulary-options" title="Sampled Vocabulary options" class="md-nav__link">
    Sampled Vocabulary options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#model-options" title="Model options" class="md-nav__link">
    Model options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#sequence-to-sequence-with-attention-options" title="Sequence to Sequence with Attention options" class="md-nav__link">
    Sequence to Sequence with Attention options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#global-attention-model-options" title="Global Attention Model options" class="md-nav__link">
    Global Attention Model options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#trainer-options" title="Trainer options" class="md-nav__link">
    Trainer options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#optimization-options" title="Optimization options" class="md-nav__link">
    Optimization options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#saver-options" title="Saver options" class="md-nav__link">
    Saver options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#translator-options" title="Translator options" class="md-nav__link">
    Translator options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#crayon-options" title="Crayon options" class="md-nav__link">
    Crayon options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#cuda-options" title="Cuda options" class="md-nav__link">
    Cuda options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#logger-options" title="Logger options" class="md-nav__link">
    Logger options
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#other-options" title="Other options" class="md-nav__link">
    Other options
  </a>
  
</li>
      
      
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          <div class="md-content">
            <article class="md-content__inner md-typeset">
              
                
                  <a href="https://github.com/OpenNMT/OpenNMT/edit/master/docs/options/train.md" title="Edit this page" class="md-icon md-content__icon">edit</a>
                
                
                  <h1>train.lua</h1>
                
                <!--- This file was automatically generated. Do not modify it manually but use the docs/options/generate.sh script instead. -->

<p><code>train.lua</code> options:</p>
<ul>
<li><code>-h [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>This help.</li>
<li><code>-md [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Dump help in Markdown format.</li>
<li><code>-config &lt;string&gt;</code> (default: <code>''</code>)<br/>Load options from this file.</li>
<li><code>-save_config &lt;string&gt;</code> (default: <code>''</code>)<br/>Save options to this file.</li>
</ul>
<h2 id="data-options">Data options<a class="headerlink" href="#data-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-data &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to the data package <code>*-train.t7</code> generated by the preprocessing step.</li>
</ul>
<h2 id="sampled-dataset-options">Sampled dataset options<a class="headerlink" href="#sampled-dataset-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-sample &lt;number&gt;</code> (default: <code>0</code>)<br/>Number of instances to sample from train data in each epoch.</li>
<li><code>-sample_type &lt;string&gt;</code> (accepted: <code>uniform</code>, <code>perplexity</code>, <code>partition</code>; default: <code>uniform</code>)<br/>Define the partition type. <code>uniform</code> draws randomly the sample, <code>perplexity</code> uses perplexity as a probability distribution when sampling (with <code>-sample_perplexity_init</code> and <code>-sample_perplexity_max</code> options), <code>partition</code> draws different subsets at each epoch.</li>
<li><code>-sample_perplexity_init &lt;number&gt;</code> (default: <code>15</code>)<br/>Start perplexity-based sampling when average train perplexity per batch falls below this value.</li>
<li><code>-sample_perplexity_max &lt;number&gt;</code> (default: <code>-1.5</code>)<br/>When greater than 0, instances with perplexity above this value will be considered as noise and ignored; when less than 0, mode + <code>-sample_perplexity_max</code> * stdev will be used as threshold.</li>
</ul>
<h2 id="data-options_1">Data options<a class="headerlink" href="#data-options_1" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-train_dir &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to training files directory.</li>
<li><code>-train_src &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to the training source data.</li>
<li><code>-train_tgt &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to the training target data.</li>
<li><code>-valid_src &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to the validation source data.</li>
<li><code>-valid_tgt &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to the validation target data.</li>
<li><code>-src_vocab &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to an existing source vocabulary.</li>
<li><code>-src_suffix &lt;string&gt;</code> (default: <code>.src</code>)<br/>Suffix for source files in train/valid directories.</li>
<li><code>-src_vocab_size &lt;table&gt;</code> (default: <code>50000</code>)<br/>List of source vocabularies size: <code>word[ feat1[ feat2[ ...] ] ]</code>. If = 0, vocabularies are not pruned.</li>
<li><code>-src_words_min_frequency &lt;table&gt;</code> (default: <code>0</code>)<br/>List of source words min frequency: <code>word[ feat1[ feat2[ ...] ] ]</code>. If = 0, vocabularies are pruned by size.</li>
<li><code>-tgt_vocab &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to an existing target vocabulary.</li>
<li><code>-tgt_suffix &lt;string&gt;</code> (default: <code>.tgt</code>)<br/>Suffix for target files in train/valid directories.</li>
<li><code>-tgt_vocab_size &lt;table&gt;</code> (default: <code>50000</code>)<br/>List of target vocabularies size: <code>word[ feat1[ feat2[ ...] ] ]</code>. If = 0, vocabularies are not pruned.</li>
<li><code>-tgt_words_min_frequency &lt;table&gt;</code> (default: <code>0</code>)<br/>List of target words min frequency: <code>word[ feat1[ feat2[ ...] ] ]</code>. If = 0, vocabularies are pruned by size.</li>
<li><code>-src_seq_length &lt;number&gt;</code> (default: <code>50</code>)<br/>Maximum source sequence length.</li>
<li><code>-tgt_seq_length &lt;number&gt;</code> (default: <code>50</code>)<br/>Maximum target sequence length.</li>
<li><code>-check_plength [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Check source and target have same length (for seq tagging).</li>
<li><code>-features_vocabs_prefix &lt;string&gt;</code> (default: <code>''</code>)<br/>Path prefix to existing features vocabularies.</li>
<li><code>-time_shift_feature [&lt;boolean&gt;]</code> (default: <code>true</code>)<br/>Time shift features on the decoder side.</li>
<li><code>-keep_frequency [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Keep frequency of words in dictionary.</li>
<li><code>-gsample &lt;number&gt;</code> (default: <code>0</code>)<br/>If not zero, extract a new sample from the corpus. In training mode, file sampling is done at each epoch. Values between 0 and 1 indicate ratio, values higher than 1 indicate data size</li>
<li><code>-gsample_dist &lt;string&gt;</code> (default: <code>''</code>)<br/>Configuration file with data class distribution to use for sampling training corpus. If not set, sampling is uniform.</li>
<li><code>-sort [&lt;boolean&gt;]</code> (default: <code>true</code>)<br/>If set, sort the sequences by size to build batches without source padding.</li>
<li><code>-shuffle [&lt;boolean&gt;]</code> (default: <code>true</code>)<br/>If set, shuffle the data (prior sorting).</li>
<li><code>-idx_files [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>If set, source and target files are 'key value' with key match between source and target.</li>
<li><code>-report_progress_every &lt;number&gt;</code> (default: <code>100000</code>)<br/>Report status every this many sentences.</li>
<li><code>-preprocess_pthreads &lt;number&gt;</code> (default: <code>4</code>)<br/>Number of parallel threads for preprocessing.</li>
</ul>
<h2 id="tokenizer-options">Tokenizer options<a class="headerlink" href="#tokenizer-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-tok_src_mode &lt;string&gt;</code> (accepted: <code>conservative</code>, <code>aggressive</code>, <code>space</code>; default: <code>space</code>)<br/>Define how aggressive should the tokenization be. <code>space</code> is space-tokenization.</li>
<li><code>-tok_tgt_mode &lt;string&gt;</code> (accepted: <code>conservative</code>, <code>aggressive</code>, <code>space</code>; default: <code>space</code>)<br/>Define how aggressive should the tokenization be. <code>space</code> is space-tokenization.</li>
<li><code>-tok_src_joiner_annotate [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Include joiner annotation using <code>-joiner</code> character.</li>
<li><code>-tok_tgt_joiner_annotate [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Include joiner annotation using <code>-joiner</code> character.</li>
<li><code>-tok_src_joiner &lt;string&gt;</code> (default: <code>￭</code>)<br/>Character used to annotate joiners.</li>
<li><code>-tok_tgt_joiner &lt;string&gt;</code> (default: <code>￭</code>)<br/>Character used to annotate joiners.</li>
<li><code>-tok_src_joiner_new [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>In <code>-joiner_annotate</code> mode, <code>-joiner</code> is an independent token.</li>
<li><code>-tok_tgt_joiner_new [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>In <code>-joiner_annotate</code> mode, <code>-joiner</code> is an independent token.</li>
<li><code>-tok_src_case_feature [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Generate case feature.</li>
<li><code>-tok_tgt_case_feature [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Generate case feature.</li>
<li><code>-tok_src_segment_case [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Segment case feature, splits AbC to Ab C to be able to restore case</li>
<li><code>-tok_tgt_segment_case [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Segment case feature, splits AbC to Ab C to be able to restore case</li>
<li><code>-tok_src_segment_alphabet &lt;table&gt;</code> (accepted: <code>Tagalog</code>, <code>Hanunoo</code>, <code>Limbu</code>, <code>Yi</code>, <code>Hebrew</code>, <code>Latin</code>, <code>Devanagari</code>, <code>Thaana</code>, <code>Lao</code>, <code>Sinhala</code>, <code>Georgian</code>, <code>Kannada</code>, <code>Cherokee</code>, <code>Kanbun</code>, <code>Buhid</code>, <code>Malayalam</code>, <code>Han</code>, <code>Thai</code>, <code>Katakana</code>, <code>Telugu</code>, <code>Greek</code>, <code>Myanmar</code>, <code>Armenian</code>, <code>Hangul</code>, <code>Cyrillic</code>, <code>Ethiopic</code>, <code>Tagbanwa</code>, <code>Gurmukhi</code>, <code>Ogham</code>, <code>Khmer</code>, <code>Arabic</code>, <code>Oriya</code>, <code>Hiragana</code>, <code>Mongolian</code>, <code>Kangxi</code>, <code>Syriac</code>, <code>Gujarati</code>, <code>Braille</code>, <code>Bengali</code>, <code>Tamil</code>, <code>Bopomofo</code>, <code>Tibetan</code>)<br/>Segment all letters from indicated alphabet.</li>
<li><code>-tok_tgt_segment_alphabet &lt;table&gt;</code> (accepted: <code>Tagalog</code>, <code>Hanunoo</code>, <code>Limbu</code>, <code>Yi</code>, <code>Hebrew</code>, <code>Latin</code>, <code>Devanagari</code>, <code>Thaana</code>, <code>Lao</code>, <code>Sinhala</code>, <code>Georgian</code>, <code>Kannada</code>, <code>Cherokee</code>, <code>Kanbun</code>, <code>Buhid</code>, <code>Malayalam</code>, <code>Han</code>, <code>Thai</code>, <code>Katakana</code>, <code>Telugu</code>, <code>Greek</code>, <code>Myanmar</code>, <code>Armenian</code>, <code>Hangul</code>, <code>Cyrillic</code>, <code>Ethiopic</code>, <code>Tagbanwa</code>, <code>Gurmukhi</code>, <code>Ogham</code>, <code>Khmer</code>, <code>Arabic</code>, <code>Oriya</code>, <code>Hiragana</code>, <code>Mongolian</code>, <code>Kangxi</code>, <code>Syriac</code>, <code>Gujarati</code>, <code>Braille</code>, <code>Bengali</code>, <code>Tamil</code>, <code>Bopomofo</code>, <code>Tibetan</code>)<br/>Segment all letters from indicated alphabet.</li>
<li><code>-tok_src_segment_numbers [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Segment numbers into single digits.</li>
<li><code>-tok_tgt_segment_numbers [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Segment numbers into single digits.</li>
<li><code>-tok_src_segment_alphabet_change [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Segment if alphabet change between 2 letters.</li>
<li><code>-tok_tgt_segment_alphabet_change [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Segment if alphabet change between 2 letters.</li>
<li><code>-tok_src_bpe_model &lt;string&gt;</code> (default: <code>''</code>)<br/>Apply Byte Pair Encoding if the BPE model path is given. If the option is used, BPE related options will be overridden/set automatically if the BPE model specified by <code>-bpe_model</code> is learnt using <code>learn_bpe.lua</code>.</li>
<li><code>-tok_tgt_bpe_model &lt;string&gt;</code> (default: <code>''</code>)<br/>Apply Byte Pair Encoding if the BPE model path is given. If the option is used, BPE related options will be overridden/set automatically if the BPE model specified by <code>-bpe_model</code> is learnt using <code>learn_bpe.lua</code>.</li>
<li><code>-tok_src_bpe_EOT_marker &lt;string&gt;</code> (default: <code>&lt;/w&gt;</code>)<br/>Marker used to mark the End of Token while applying BPE in mode 'prefix' or 'both'.</li>
<li><code>-tok_tgt_bpe_EOT_marker &lt;string&gt;</code> (default: <code>&lt;/w&gt;</code>)<br/>Marker used to mark the End of Token while applying BPE in mode 'prefix' or 'both'.</li>
<li><code>-tok_src_bpe_BOT_marker &lt;string&gt;</code> (default: <code>&lt;w&gt;</code>)<br/>Marker used to mark the Beginning of Token while applying BPE in mode 'suffix' or 'both'.</li>
<li><code>-tok_tgt_bpe_BOT_marker &lt;string&gt;</code> (default: <code>&lt;w&gt;</code>)<br/>Marker used to mark the Beginning of Token while applying BPE in mode 'suffix' or 'both'.</li>
<li><code>-tok_src_bpe_case_insensitive [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Apply BPE internally in lowercase, but still output the truecase units. This option will be overridden/set automatically if the BPE model specified by <code>-bpe_model</code> is learnt using <code>learn_bpe.lua</code>.</li>
<li><code>-tok_tgt_bpe_case_insensitive [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Apply BPE internally in lowercase, but still output the truecase units. This option will be overridden/set automatically if the BPE model specified by <code>-bpe_model</code> is learnt using <code>learn_bpe.lua</code>.</li>
<li><code>-tok_src_bpe_mode &lt;string&gt;</code> (accepted: <code>suffix</code>, <code>prefix</code>, <code>both</code>, <code>none</code>; default: <code>suffix</code>)<br/>Define the BPE mode. This option will be overridden/set automatically if the BPE model specified by <code>-bpe_model</code> is learnt using <code>learn_bpe.lua</code>. <code>prefix</code>: append <code>-bpe_BOT_marker</code> to the begining of each word to learn prefix-oriented pair statistics; <code>suffix</code>: append <code>-bpe_EOT_marker</code> to the end of each word to learn suffix-oriented pair statistics, as in the original Python script; <code>both</code>: <code>suffix</code> and <code>prefix</code>; <code>none</code>: no <code>suffix</code> nor <code>prefix</code>.</li>
<li><code>-tok_tgt_bpe_mode &lt;string&gt;</code> (accepted: <code>suffix</code>, <code>prefix</code>, <code>both</code>, <code>none</code>; default: <code>suffix</code>)<br/>Define the BPE mode. This option will be overridden/set automatically if the BPE model specified by <code>-bpe_model</code> is learnt using <code>learn_bpe.lua</code>. <code>prefix</code>: append <code>-bpe_BOT_marker</code> to the begining of each word to learn prefix-oriented pair statistics; <code>suffix</code>: append <code>-bpe_EOT_marker</code> to the end of each word to learn suffix-oriented pair statistics, as in the original Python script; <code>both</code>: <code>suffix</code> and <code>prefix</code>; <code>none</code>: no <code>suffix</code> nor <code>prefix</code>.</li>
<li><code>-tok_src_normalize_cmd &lt;string&gt;</code> (default: <code>''</code>)<br/>Command for on-the-fly corpus normalization. It should work in 'pipeline' mode.</li>
<li><code>-tok_tgt_normalize_cmd &lt;string&gt;</code> (default: <code>''</code>)<br/>Command for on-the-fly corpus normalization. It should work in 'pipeline' mode.</li>
</ul>
<h2 id="sampled-vocabulary-options">Sampled Vocabulary options<a class="headerlink" href="#sampled-vocabulary-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-sample_vocab [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Use importance sampling as an approximation of the full output vocabulary softmax.</li>
</ul>
<h2 id="model-options">Model options<a class="headerlink" href="#model-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-model_type &lt;string&gt;</code> (accepted: <code>lm</code>, <code>seq2seq</code>, <code>seqtagger</code>; default: <code>seq2seq</code>)<br/>Type of model to train. This option impacts all options choices.</li>
<li><code>-param_init &lt;number&gt;</code> (default: <code>0.1</code>)<br/>Parameters are initialized over uniform distribution with support (-<code>param_init</code>, <code>param_init</code>). Set to 0 to rely on each module default initialization.</li>
</ul>
<h2 id="sequence-to-sequence-with-attention-options">Sequence to Sequence with Attention options<a class="headerlink" href="#sequence-to-sequence-with-attention-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-enc_layers &lt;number&gt;</code> (default: <code>0</code>)<br/>If &gt; 0, number of layers of the encoder. This overrides the global <code>-layers</code> option.</li>
<li><code>-dec_layers &lt;number&gt;</code> (default: <code>0</code>)<br/>If &gt; 0, number of layers of the decoder. This overrides the global <code>-layers</code> option.</li>
<li><code>-word_vec_size &lt;number&gt;</code> (default: <code>0</code>)<br/>Shared word embedding size. If set, this overrides <code>-src_word_vec_size</code> and <code>-tgt_word_vec_size</code>.</li>
<li><code>-src_word_vec_size &lt;table&gt;</code> (default: <code>500</code>)<br/>List of source embedding sizes: <code>word[ feat1[ feat2[ ...] ] ]</code>.</li>
<li><code>-tgt_word_vec_size &lt;table&gt;</code> (default: <code>500</code>)<br/>List of target embedding sizes: <code>word[ feat1[ feat2[ ...] ] ]</code>.</li>
<li><code>-pre_word_vecs_enc &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to pretrained word embeddings on the encoder side serialized as a Torch tensor.</li>
<li><code>-pre_word_vecs_dec &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to pretrained word embeddings on the decoder side serialized as a Torch tensor.</li>
<li><code>-fix_word_vecs_enc [&lt;boolean&gt;/&lt;string&gt;]</code> (accepted: <code>false</code>, <code>true</code>, <code>pretrained</code>; default: <code>false</code>)<br/>Fix word embeddings on the encoder side.</li>
<li><code>-fix_word_vecs_dec [&lt;boolean&gt;/&lt;string&gt;]</code> (accepted: <code>false</code>, <code>true</code>, <code>pretrained</code>; default: <code>false</code>)<br/>Fix word embeddings on the decoder side.</li>
<li><code>-feat_merge &lt;string&gt;</code> (accepted: <code>concat</code>, <code>sum</code>; default: <code>concat</code>)<br/>Merge action for the features embeddings.</li>
<li><code>-feat_vec_exponent &lt;number&gt;</code> (default: <code>0.7</code>)<br/>When features embedding sizes are not set and using <code>-feat_merge concat</code>, their dimension will be set to <code>N^feat_vec_exponent</code> where <code>N</code> is the number of values the feature takes.</li>
<li><code>-feat_vec_size &lt;number&gt;</code> (default: <code>20</code>)<br/>When features embedding sizes are not set and using <code>-feat_merge sum</code>, this is the common embedding size of the features</li>
<li><code>-layers &lt;number&gt;</code> (default: <code>2</code>)<br/>Number of recurrent layers of the encoder and decoder. See also <code>-enc_layers</code>, <code>-dec_layers</code> and <code>-bridge</code> to assign different layers to the encoder and decoder.</li>
<li><code>-rnn_size &lt;number&gt;</code> (default: <code>500</code>)<br/>Hidden size of the recurrent unit.</li>
<li><code>-rnn_type &lt;string&gt;</code> (accepted: <code>LSTM</code>, <code>GRU</code>; default: <code>LSTM</code>)<br/>Type of recurrent cell.</li>
<li><code>-dropout &lt;number&gt;</code> (default: <code>0.3</code>)<br/>Dropout probability applied between recurrent layers.</li>
<li><code>-dropout_input [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Dropout probability applied to the input of the recurrent module.</li>
<li><code>-dropout_words &lt;number&gt;</code> (default: <code>0</code>)<br/>Dropout probability applied to the source sequence.</li>
<li><code>-dropout_type &lt;string&gt;</code> (accepted: <code>naive</code>, <code>variational</code>; default: <code>naive</code>)<br/>Dropout type.</li>
<li><code>-residual [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Add residual connections between recurrent layers.</li>
<li><code>-bridge &lt;string&gt;</code> (accepted: <code>copy</code>, <code>dense</code>, <code>dense_nonlinear</code>, <code>none</code>; default: <code>copy</code>)<br/>Define how to pass encoder states to the decoder. With <code>copy</code>, the encoder and decoder must have the same number of layers.</li>
<li><code>-input_feed [&lt;boolean&gt;]</code> (default: <code>true</code>)<br/>Feed the context vector at each time step as additional input (via concatenation with the word embeddings) to the decoder.</li>
<li><code>-scheduled_sampling &lt;number&gt;</code> (default: <code>1</code>)<br/>Probability of feeding true (vs. generated) previous token to decoder.</li>
<li><code>-scheduled_sampling_scope &lt;string&gt;</code> (accepted: <code>token</code>, <code>sentence</code>; default: <code>token</code>)<br/>Apply scheduled sampling at token or sentence level.</li>
<li><code>-scheduled_sampling_decay_type &lt;string&gt;</code> (accepted: <code>linear</code>, <code>invsigmoid</code>; default: <code>linear</code>)<br/>Scheduled Sampling decay type.</li>
<li><code>-scheduled_sampling_decay_rate &lt;number&gt;</code> (default: <code>0</code>)<br/>Scheduled Sampling decay rate.</li>
<li><code>-encoder_type &lt;string&gt;</code> (accepted: <code>rnn</code>, <code>brnn</code>, <code>dbrnn</code>, <code>pdbrnn</code>, <code>gnmt</code>, <code>cnn</code>; default: <code>rnn</code>)<br/>Encoder type.</li>
<li><code>-attention &lt;string&gt;</code> (accepted: <code>none</code>, <code>global</code>; default: <code>global</code>)<br/>Attention model.</li>
<li><code>-brnn_merge &lt;string&gt;</code> (accepted: <code>concat</code>, <code>sum</code>; default: <code>sum</code>)<br/>Merge action for the bidirectional states.</li>
<li><code>-pdbrnn_reduction &lt;number&gt;</code> (default: <code>2</code>)<br/>Time-reduction factor at each layer.</li>
<li><code>-pdbrnn_merge &lt;string&gt;</code> (accepted: <code>concat</code>, <code>sum</code>; default: <code>concat</code>)<br/>Merge action when reducing time.</li>
<li><code>-cnn_layers &lt;number&gt;</code> (default: <code>2</code>)<br/>Number of convolutional layers in the encoder.</li>
<li><code>-cnn_kernel &lt;number&gt;</code> (default: <code>3</code>)<br/>Kernel size for convolutions. Same in each layer.</li>
<li><code>-cnn_size &lt;number&gt;</code> (default: <code>500</code>)<br/>Number of output units per convolutional layer. Same in each layer.</li>
<li><code>-use_pos_emb [&lt;boolean&gt;]</code> (default: <code>true</code>)<br/>Add positional embeddings to word embeddings.</li>
<li><code>-max_pos &lt;number&gt;</code> (default: <code>50</code>)<br/>Maximum value for positional indexes.</li>
</ul>
<h2 id="global-attention-model-options">Global Attention Model options<a class="headerlink" href="#global-attention-model-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-global_attention &lt;string&gt;</code> (accepted: <code>general</code>, <code>dot</code>, <code>concat</code>; default: <code>general</code>)<br/>Global attention model type.</li>
</ul>
<h2 id="trainer-options">Trainer options<a class="headerlink" href="#trainer-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-save_every &lt;number&gt;</code> (default: <code>5000</code>)<br/>Save intermediate models every this many iterations within an epoch. If = 0, will not save intermediate models.</li>
<li><code>-save_every_epochs &lt;number&gt;</code> (default: <code>1</code>)<br/>Save a model every this many epochs. If = 0, will not save a model at each epoch.</li>
<li><code>-report_every &lt;number&gt;</code> (default: <code>50</code>)<br/>Report progress every this many iterations within an epoch.</li>
<li><code>-async_parallel [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>When training on multiple GPUs, update parameters asynchronously.</li>
<li><code>-async_parallel_minbatch &lt;number&gt;</code> (default: <code>1000</code>)<br/>In asynchronous training, minimal number of sequential batches before being parallel.</li>
<li><code>-start_iteration &lt;number&gt;</code> (default: <code>1</code>)<br/>If loading from a checkpoint, the iteration from which to start.</li>
<li><code>-start_epoch &lt;number&gt;</code> (default: <code>1</code>)<br/>If loading from a checkpoint, the epoch from which to start.</li>
<li><code>-end_epoch &lt;number&gt;</code> (default: <code>13</code>)<br/>The final epoch of the training. If = 0, train forever unless another stopping condition is met (e.g. <code>-min_learning_rate</code> is reached).</li>
<li><code>-curriculum &lt;number&gt;</code> (default: <code>0</code>)<br/>For this many epochs, order the minibatches based on source length (from smaller to longer). Sometimes setting this to 1 will increase convergence speed.</li>
<li><code>-validation_metric &lt;string&gt;</code> (accepted: <code>perplexity</code>, <code>loss</code>, <code>bleu</code>, <code>ter</code>, <code>dlratio</code>; default: <code>perplexity</code>)<br/>Metric to use for validation.</li>
<li><code>-save_validation_translation_every &lt;number&gt;</code> (default: <code>0</code>)<br/>When using translation-based validation metrics (e.g. BLEU, TER, etc.), also save the translation every this many epochs to the file <code>&lt;save_model&gt;_epochN_validation_translation.txt</code>. If = 0, will not save validation translation.</li>
</ul>
<h2 id="optimization-options">Optimization options<a class="headerlink" href="#optimization-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-max_batch_size &lt;number&gt;</code> (default: <code>64</code>)<br/>Maximum batch size.</li>
<li><code>-uneven_batches [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>If set, batches are filled up to <code>-max_batch_size</code> even if the source lengths are different. Slower but needed for some tasks.</li>
<li><code>-optim &lt;string&gt;</code> (accepted: <code>sgd</code>, <code>adagrad</code>, <code>adadelta</code>, <code>adam</code>; default: <code>sgd</code>)<br/>Optimization method.</li>
<li><code>-learning_rate &lt;number&gt;</code> (default: <code>1</code>)<br/>Initial learning rate. If <code>adagrad</code> or <code>adam</code> is used, then this is the global learning rate. Recommended settings are: <code>sgd</code> = 1, <code>adagrad</code> = 0.1, <code>adam</code> = 0.0002.</li>
<li><code>-min_learning_rate &lt;number&gt;</code> (default: <code>0</code>)<br/>Do not continue the training past this learning rate value.</li>
<li><code>-max_grad_norm &lt;number&gt;</code> (default: <code>5</code>)<br/>Clip the gradients L2-norm to this value. Set to 0 to disable.</li>
<li><code>-learning_rate_decay &lt;number&gt;</code> (default: <code>0.7</code>)<br/>Learning rate decay factor: <code>learning_rate = learning_rate * learning_rate_decay</code>.</li>
<li><code>-start_decay_at &lt;number&gt;</code> (default: <code>9</code>)<br/>In "default" decay mode, start decay after this epoch.</li>
<li><code>-start_decay_score_delta &lt;number&gt;</code> (default: <code>0</code>)<br/>Start decay when validation score improvement is lower than this value.</li>
<li><code>-decay &lt;string&gt;</code> (accepted: <code>default</code>, <code>epoch_only</code>, <code>score_only</code>; default: <code>default</code>)<br/>When to apply learning rate decay. <code>default</code>: decay after each epoch past <code>-start_decay_at</code> or as soon as the validation score is not improving more than <code>-start_decay_score_delta</code>, <code>epoch_only</code>: only decay after each epoch past <code>-start_decay_at</code>, <code>score_only</code>: only decay when validation score is not improving more than <code>-start_decay_score_delta</code>.</li>
<li><code>-decay_method &lt;string&gt;</code> (accepted: <code>default</code>, <code>restart</code>; default: <code>default</code>)<br/>If <code>restart</code> is set, the optimizer states (if any) will be reset when the decay condition is met.</li>
</ul>
<h2 id="saver-options">Saver options<a class="headerlink" href="#saver-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-save_model &lt;string&gt;</code> (required)<br/>Model filename (the model will be saved as <code>&lt;save_model&gt;_epochN_PPL.t7</code> where <code>PPL</code> is the validation perplexity.</li>
<li><code>-train_from &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to a checkpoint.</li>
<li><code>-continue [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>If set, continue the training where it left off.</li>
</ul>
<h2 id="translator-options">Translator options<a class="headerlink" href="#translator-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-model &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to the serialized model file.</li>
<li><code>-lm_model &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to serialized language model file.</li>
<li><code>-lm_weight &lt;number&gt;</code> (default: <code>0.1</code>)<br/>Relative weight of language model.</li>
<li><code>-beam_size &lt;number&gt;</code> (default: <code>5</code>)<br/>Beam size.</li>
<li><code>-max_sent_length &lt;number&gt;</code> (default: <code>250</code>)<br/>Maximum output sentence length.</li>
<li><code>-replace_unk [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Replace the generated <unk> tokens with the source token that has the highest attention weight. If <code>-phrase_table</code> is provided, it will lookup the identified source token and give the corresponding target token. If it is not provided (or the identified source token does not exist in the table) then it will copy the source token</li>
<li><code>-replace_unk_tagged [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>The same as -replace_unk, but wrap the replaced token in ｟unk:xxxxx｠ if it is not found in the phrase table.</li>
<li><code>-phrase_table &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to source-target dictionary to replace <code>&lt;unk&gt;</code> tokens.</li>
<li><code>-n_best &lt;number&gt;</code> (default: <code>1</code>)<br/>If &gt; 1, it will also output an n-best list of decoded sentences.</li>
<li><code>-max_num_unks &lt;number&gt;</code> (default: <code>inf</code>)<br/>All sequences with more <code>&lt;unk&gt;</code>s than this will be ignored during beam search.</li>
<li><code>-target_subdict &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to target words dictionary corresponding to the source.</li>
<li><code>-pre_filter_factor &lt;number&gt;</code> (default: <code>1</code>)<br/>Optional, set this only if filter is being used. Before applying filters, hypotheses with top <code>beam_size * pre_filter_factor</code> scores will be considered. If the returned hypotheses voilate filters, then set this to a larger value to consider more.</li>
<li><code>-length_norm &lt;number&gt;</code> (default: <code>0</code>)<br/>Length normalization coefficient (alpha). If set to 0, no length normalization.</li>
<li><code>-coverage_norm &lt;number&gt;</code> (default: <code>0</code>)<br/>Coverage normalization coefficient (beta). An extra coverage term multiplied by beta is added to hypotheses scores. If is set to 0, no coverage normalization.</li>
<li><code>-eos_norm &lt;number&gt;</code> (default: <code>0</code>)<br/>End of sentence normalization coefficient (gamma). If set to 0, no EOS normalization.</li>
<li><code>-dump_input_encoding [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Instead of generating target tokens conditional on the source tokens, we print the representation (encoding/embedding) of the input.</li>
<li><code>-save_beam_to &lt;string&gt;</code> (default: <code>''</code>)<br/>Path to a file where the beam search exploration will be saved in a JSON format. Requires the <code>dkjson</code> package.</li>
</ul>
<h2 id="crayon-options">Crayon options<a class="headerlink" href="#crayon-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-exp_host &lt;string&gt;</code> (default: <code>127.0.0.1</code>)<br/>Crayon server IP.</li>
<li><code>-exp_port &lt;string&gt;</code> (default: <code>8889</code>)<br/>Crayon server port.</li>
<li><code>-exp &lt;string&gt;</code> (default: <code>''</code>)<br/>Crayon experiment name.</li>
</ul>
<h2 id="cuda-options">Cuda options<a class="headerlink" href="#cuda-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-gpuid &lt;table&gt;</code> (default: <code>0</code>)<br/>List of GPU identifiers (1-indexed). CPU is used when set to 0.</li>
<li><code>-fallback_to_cpu [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>If GPU can't be used, rollback on the CPU.</li>
<li><code>-fp16 [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Use half-precision float on GPU.</li>
<li><code>-no_nccl [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Disable usage of nccl in parallel mode.</li>
</ul>
<h2 id="logger-options">Logger options<a class="headerlink" href="#logger-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-log_file &lt;string&gt;</code> (default: <code>''</code>)<br/>Output logs to a file under this path instead of stdout - if file name ending with json, output structure json.</li>
<li><code>-disable_logs [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>If set, output nothing.</li>
<li><code>-log_level &lt;string&gt;</code> (accepted: <code>DEBUG</code>, <code>INFO</code>, <code>WARNING</code>, <code>ERROR</code>, <code>NOERROR</code>; default: <code>INFO</code>)<br/>Output logs at this level and above.</li>
</ul>
<h2 id="other-options">Other options<a class="headerlink" href="#other-options" title="Permanent link">&para;</a></h2>
<ul>
<li><code>-disable_mem_optimization [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Disable sharing of internal buffers between clones for visualization or development.</li>
<li><code>-profiler [&lt;boolean&gt;]</code> (default: <code>false</code>)<br/>Generate profiling logs.</li>
<li><code>-seed &lt;number&gt;</code> (default: <code>3435</code>)<br/>Random seed.</li>
</ul>
                
                  
                
              
              
                
              
            </article>
          </div>
        </div>
      </main>
      
        
<footer class="md-footer">
  
    <div class="md-footer-nav">
      <nav class="md-footer-nav__inner md-grid">
        
          <a href="../preprocess/" title="preprocess.lua" class="md-flex md-footer-nav__link md-footer-nav__link--prev" rel="prev">
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-back md-footer-nav__button"></i>
            </div>
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Previous
                </span>
                preprocess.lua
              </span>
            </div>
          </a>
        
        
          <a href="../translate/" title="translate.lua" class="md-flex md-footer-nav__link md-footer-nav__link--next" rel="next">
            <div class="md-flex__cell md-flex__cell--stretch md-footer-nav__title">
              <span class="md-flex__ellipsis">
                <span class="md-footer-nav__direction">
                  Next
                </span>
                translate.lua
              </span>
            </div>
            <div class="md-flex__cell md-flex__cell--shrink">
              <i class="md-icon md-icon--arrow-forward md-footer-nav__button"></i>
            </div>
          </a>
        
      </nav>
    </div>
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-footer-copyright">
        
        powered by
        <a href="http://www.mkdocs.org" title="MkDocs">MkDocs</a>
        and
        <a href="http://squidfunk.github.io/mkdocs-material/" title="Material for MkDocs">
          Material for MkDocs</a>
      </div>
      
        
  <div class="md-footer-social">
    
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css">
    
      <a href="http://opennmt.net" class="md-footer-social__link fa fa-globe"></a>
    
      <a href="https://github.com/OpenNMT/OpenNMT" class="md-footer-social__link fa fa-github"></a>
    
  </div>

      
    </div>
  </div>
</footer>
      
    </div>
    
      <script src="../../assets/javascripts/application-ad1183cb07.js"></script>
      <script>app.initialize({url:{base:"../.."}})</script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_HTMLorMML"></script>
      
        <script src="http://opennmt.net/OpenNMT/js/version-select.js"></script>
      
        <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"></script>
      
        <script src="https://cdnjs.cloudflare.com/ajax/libs/select2/4.0.4/js/select2.min.js"></script>
      
    
    
      
      <script>!function(e,t,a,n,o,c,i){e.GoogleAnalyticsObject=o,e[o]=e[o]||function(){(e[o].q=e[o].q||[]).push(arguments)},e[o].l=1*new Date,c=t.createElement(a),i=t.getElementsByTagName(a)[0],c.async=1,c.src=n,i.parentNode.insertBefore(c,i)}(window,document,"script","https://www.google-analytics.com/analytics.js","ga"),ga("create","UA-89222039-1","opennmt.net"),ga("set","anonymizeIp",!0),ga("send","pageview");var links=document.getElementsByTagName("a");Array.prototype.map.call(links,function(e){e.host!=document.location.host&&e.addEventListener("click",function(){var t=e.getAttribute("data-md-action")||"follow";ga("send","event","outbound",t,e.href)})});var query=document.forms.search.query;query.addEventListener("blur",function(){if(this.value){var e=document.location.pathname;ga("send","pageview",e+"?q="+this.value)}})</script>
      
    
  </body>
</html>